{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Model a Deep Feed Forward Network for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Generating Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have generated the training data according to functions given in the homework. x(n) range (0,1)\n",
    "y(n) noise = 0.001.\n",
    "\n",
    "I've used 600 training and 100 test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.830197</td>\n",
       "      <td>0.405060</td>\n",
       "      <td>0.810531</td>\n",
       "      <td>0.534717</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.152219</td>\n",
       "      <td>0.940788</td>\n",
       "      <td>0.597202</td>\n",
       "      <td>0.913253</td>\n",
       "      <td>-2.405616</td>\n",
       "      <td>-0.060698</td>\n",
       "      <td>-3.410864</td>\n",
       "      <td>-4.221637</td>\n",
       "      <td>-1.458062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.973353</td>\n",
       "      <td>0.199305</td>\n",
       "      <td>0.669345</td>\n",
       "      <td>0.676851</td>\n",
       "      <td>0.949700</td>\n",
       "      <td>0.678318</td>\n",
       "      <td>0.218934</td>\n",
       "      <td>0.236650</td>\n",
       "      <td>0.676503</td>\n",
       "      <td>1.128159</td>\n",
       "      <td>1.544336</td>\n",
       "      <td>-4.638862</td>\n",
       "      <td>-1.557873</td>\n",
       "      <td>-2.750525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.827533</td>\n",
       "      <td>0.052860</td>\n",
       "      <td>0.579171</td>\n",
       "      <td>0.407109</td>\n",
       "      <td>0.575590</td>\n",
       "      <td>0.942033</td>\n",
       "      <td>0.329652</td>\n",
       "      <td>0.176601</td>\n",
       "      <td>0.017851</td>\n",
       "      <td>0.425506</td>\n",
       "      <td>1.390903</td>\n",
       "      <td>-2.986235</td>\n",
       "      <td>-0.242590</td>\n",
       "      <td>-3.511871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.704136</td>\n",
       "      <td>0.693992</td>\n",
       "      <td>0.119481</td>\n",
       "      <td>0.553727</td>\n",
       "      <td>0.163137</td>\n",
       "      <td>0.158602</td>\n",
       "      <td>0.480594</td>\n",
       "      <td>0.919685</td>\n",
       "      <td>0.675119</td>\n",
       "      <td>-2.871702</td>\n",
       "      <td>0.221924</td>\n",
       "      <td>-4.540541</td>\n",
       "      <td>-3.353122</td>\n",
       "      <td>-1.629102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.808557</td>\n",
       "      <td>0.393863</td>\n",
       "      <td>0.702464</td>\n",
       "      <td>0.576224</td>\n",
       "      <td>0.912895</td>\n",
       "      <td>0.940665</td>\n",
       "      <td>0.419981</td>\n",
       "      <td>0.376427</td>\n",
       "      <td>0.110196</td>\n",
       "      <td>0.631071</td>\n",
       "      <td>1.697203</td>\n",
       "      <td>-4.990213</td>\n",
       "      <td>-1.941839</td>\n",
       "      <td>-3.588780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  0.830197  0.405060  0.810531  0.534717  0.074752  0.152219  0.940788   \n",
       "1  0.973353  0.199305  0.669345  0.676851  0.949700  0.678318  0.218934   \n",
       "2  0.827533  0.052860  0.579171  0.407109  0.575590  0.942033  0.329652   \n",
       "3  0.704136  0.693992  0.119481  0.553727  0.163137  0.158602  0.480594   \n",
       "4  0.808557  0.393863  0.702464  0.576224  0.912895  0.940665  0.419981   \n",
       "\n",
       "         x7        x8        y0        y1        y2        y3        y4  \n",
       "0  0.597202  0.913253 -2.405616 -0.060698 -3.410864 -4.221637 -1.458062  \n",
       "1  0.236650  0.676503  1.128159  1.544336 -4.638862 -1.557873 -2.750525  \n",
       "2  0.176601  0.017851  0.425506  1.390903 -2.986235 -0.242590 -3.511871  \n",
       "3  0.919685  0.675119 -2.871702  0.221924 -4.540541 -3.353122 -1.629102  \n",
       "4  0.376427  0.110196  0.631071  1.697203 -4.990213 -1.941839 -3.588780  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "\n",
    "#define 9 dimensional x (input) numpy array\n",
    "x = np.zeros(9, np.float64)\n",
    "\n",
    "#define 5 dimensional y (output) numpy array\n",
    "y = np.zeros(5, np.float64)\n",
    "\n",
    "#define y functions\n",
    "# y[0] = (2 * x[0] * x[1] * x[2]) + (x[3] * x[4]) - (3 * x[5] * x[6] * x[7]) - (7 * x[0] ** 2 * x[7]) + (2 * x[4])\n",
    "# y[1] = (2 * x[0] * x[4] * x[5]) - (x[2] * x[3] - 3 * x[1] * x[2] * x[3]) - x[2] ** 2 * x[4] - (2 * x[6] * x[7]) + 1\n",
    "# y[2] = (x[2] ** 2) - (x[4] * x[6]) - (3 * x[0] * x[3] * x[5]) - (12 * x[0] ** 2 * x[1] * x[3]) - 2\n",
    "# y[3] = (x[5] ** 3) - (5 * x[0] * x[2] * x[7]) - (x[0] * x[3] * x[6]) - (2 * x[4] ** 2 * x[1] * x[3]) - 3 * x[7]\n",
    "# y[4] = (x[2] ** 2 * x[4]) - (2 * x[2] * x[3] * x[7]) - (x[0] * x[1] * x[3]) - (3 * x[5]) + (x[0] ** 2 * x[6]) - 1\n",
    "\n",
    "fh = open(\"training_data.txt\",\"w\")\n",
    "\n",
    "\n",
    "#generate random inputs for every iteration\n",
    "def generate_random_x():\n",
    "    for index, x_i in enumerate(x):\n",
    "        #x[index] = rnd.uniform(0, 100)\n",
    "        x[index] = rnd.random()\n",
    "        # x[index] = rnd.randint(0, 10000)\n",
    "        \n",
    "def calculate_y():\n",
    "    generate_random_x()\n",
    "    # y1 = 2*x1 * x2 * x3 + x4 * x5 - 3*x6 * x7 * x8 - 7*x1^2 * x8 + 2*x5\n",
    "    # if index == 0:\n",
    "    y[0] = (2 * x[0] * x[1] * x[2]) + (x[3] * x[4]) - (3 * x[5] * x[6] * x[7]) - (7 * x[0] ** 2 * x[7]) + (2 * x[4])\n",
    "    # elif index == 1:\n",
    "    y[1] = (2 * x[0] * x[4] * x[5]) - (x[2] * x[3] - 3 * x[1] * x[2] * x[3]) - x[2] ** 2 * x[4] - (\n",
    "            2 * x[6] * x[7]) + 1\n",
    "    # elif index == 2:\n",
    "    y[2] = (x[2] ** 2) - (x[4] * x[6]) - (3 * x[0] * x[3] * x[5]) - (12 * x[0] ** 2 * x[1] * x[3]) - 2\n",
    "    # elif index == 3:\n",
    "    y[3] = (x[5] ** 3) - (5 * x[0] * x[2] * x[7]) - (x[0] * x[3] * x[6]) - (2 * x[4] ** 2 * x[1] * x[3]) - 3 * x[7]\n",
    "    # elif index == 4:\n",
    "    y[4] = (x[2] ** 2 * x[4]) - (2 * x[2] * x[3] * x[7]) - (x[0] * x[1] * x[3]) - (3 * x[5]) + (\n",
    "            x[0] ** 2 * x[6]) - 1\n",
    "\n",
    "    # write x to file\n",
    "    for x_i in x:\n",
    "        fh.write(str(x_i))\n",
    "        fh.write(\" \")\n",
    "\n",
    "    # write y to file\n",
    "    for y_i in range(0, 5, 1):\n",
    "        # if index == y_i:\n",
    "        # some noise added.\n",
    "        y[y_i] += y[y_i] * 0.001\n",
    "        fh.write(str(y[y_i]))\n",
    "        # else:\n",
    "        #    fh.write(\"0\")\n",
    "\n",
    "        if y_i != 4:\n",
    "            fh.write(\" \")\n",
    "\n",
    "    # fh.write(' y' + str(index))\n",
    "    fh.write(\"\\n\")\n",
    "\n",
    "#generate 600 training samples.\n",
    "for i in range(0, 120, 1):\n",
    "\n",
    "    for j in range(0, 5, 1):\n",
    "        calculate_y()\n",
    "\n",
    "fh.close()\n",
    "\n",
    "column_names = ['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'y0', 'y1', 'y2', 'y3', 'y4']\n",
    "\n",
    "df = pd.read_csv(\"training_data.txt\", header=None, delimiter=' ')\n",
    "\n",
    "df.columns = column_names\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Generating Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.245465</td>\n",
       "      <td>0.806462</td>\n",
       "      <td>0.168295</td>\n",
       "      <td>0.288156</td>\n",
       "      <td>0.192200</td>\n",
       "      <td>0.481675</td>\n",
       "      <td>0.855922</td>\n",
       "      <td>0.547640</td>\n",
       "      <td>0.692298</td>\n",
       "      <td>-0.401903</td>\n",
       "      <td>0.171365</td>\n",
       "      <td>-2.406420</td>\n",
       "      <td>-1.721992</td>\n",
       "      <td>-2.498168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.789376</td>\n",
       "      <td>0.066095</td>\n",
       "      <td>0.803115</td>\n",
       "      <td>0.450522</td>\n",
       "      <td>0.252928</td>\n",
       "      <td>0.358469</td>\n",
       "      <td>0.830949</td>\n",
       "      <td>0.388864</td>\n",
       "      <td>0.381966</td>\n",
       "      <td>-1.340031</td>\n",
       "      <td>0.043673</td>\n",
       "      <td>-2.170280</td>\n",
       "      <td>-2.652472</td>\n",
       "      <td>-1.699399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.657389</td>\n",
       "      <td>0.191691</td>\n",
       "      <td>0.915481</td>\n",
       "      <td>0.918482</td>\n",
       "      <td>0.406989</td>\n",
       "      <td>0.605684</td>\n",
       "      <td>0.018028</td>\n",
       "      <td>0.582669</td>\n",
       "      <td>0.566281</td>\n",
       "      <td>-0.363213</td>\n",
       "      <td>0.604693</td>\n",
       "      <td>-3.179427</td>\n",
       "      <td>-3.348355</td>\n",
       "      <td>-3.563785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.380789</td>\n",
       "      <td>0.518216</td>\n",
       "      <td>0.065146</td>\n",
       "      <td>0.537759</td>\n",
       "      <td>0.575871</td>\n",
       "      <td>0.159791</td>\n",
       "      <td>0.166783</td>\n",
       "      <td>0.267672</td>\n",
       "      <td>0.796949</td>\n",
       "      <td>1.194045</td>\n",
       "      <td>0.997780</td>\n",
       "      <td>-2.674861</td>\n",
       "      <td>-1.051122</td>\n",
       "      <td>-1.577618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016613</td>\n",
       "      <td>0.445442</td>\n",
       "      <td>0.462649</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.295861</td>\n",
       "      <td>0.289448</td>\n",
       "      <td>0.719912</td>\n",
       "      <td>0.832413</td>\n",
       "      <td>0.359258</td>\n",
       "      <td>0.204406</td>\n",
       "      <td>-0.191790</td>\n",
       "      <td>-2.005819</td>\n",
       "      <td>-2.543834</td>\n",
       "      <td>-2.140753</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  0.245465  0.806462  0.168295  0.288156  0.192200  0.481675  0.855922   \n",
       "1  0.789376  0.066095  0.803115  0.450522  0.252928  0.358469  0.830949   \n",
       "2  0.657389  0.191691  0.915481  0.918482  0.406989  0.605684  0.018028   \n",
       "3  0.380789  0.518216  0.065146  0.537759  0.575871  0.159791  0.166783   \n",
       "4  0.016613  0.445442  0.462649  0.432000  0.295861  0.289448  0.719912   \n",
       "\n",
       "         x7        x8        y0        y1        y2        y3        y4  \n",
       "0  0.547640  0.692298 -0.401903  0.171365 -2.406420 -1.721992 -2.498168  \n",
       "1  0.388864  0.381966 -1.340031  0.043673 -2.170280 -2.652472 -1.699399  \n",
       "2  0.582669  0.566281 -0.363213  0.604693 -3.179427 -3.348355 -3.563785  \n",
       "3  0.267672  0.796949  1.194045  0.997780 -2.674861 -1.051122 -1.577618  \n",
       "4  0.832413  0.359258  0.204406 -0.191790 -2.005819 -2.543834 -2.140753  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fh_test = open(\"test_data.txt\", \"w\")\n",
    "\n",
    "def calculate_test_y():\n",
    "    generate_random_x()\n",
    "    # y1 = 2*x1 * x2 * x3 + x4 * x5 - 3*x6 * x7 * x8 - 7*x1^2 * x8 + 2*x5\n",
    "    # if index == 0:\n",
    "    y[0] = (2 * x[0] * x[1] * x[2]) + (x[3] * x[4]) - (3 * x[5] * x[6] * x[7]) - (7 * x[0] ** 2 * x[7]) + (2 * x[4])\n",
    "    # elif index == 1:\n",
    "    y[1] = (2 * x[0] * x[4] * x[5]) - (x[2] * x[3] - 3 * x[1] * x[2] * x[3]) - x[2] ** 2 * x[4] - (\n",
    "            2 * x[6] * x[7]) + 1\n",
    "    # elif index == 2:\n",
    "    y[2] = (x[2] ** 2) - (x[4] * x[6]) - (3 * x[0] * x[3] * x[5]) - (12 * x[0] ** 2 * x[1] * x[3]) - 2\n",
    "    # elif index == 3:\n",
    "    y[3] = (x[5] ** 3) - (5 * x[0] * x[2] * x[7]) - (x[0] * x[3] * x[6]) - (2 * x[4] ** 2 * x[1] * x[3]) - 3 * x[7]\n",
    "    # elif index == 4:\n",
    "    y[4] = (x[2] ** 2 * x[4]) - (2 * x[2] * x[3] * x[7]) - (x[0] * x[1] * x[3]) - (3 * x[5]) + (\n",
    "            x[0] ** 2 * x[6]) - 1\n",
    "\n",
    "    # write x to file\n",
    "    for x_i in x:\n",
    "        fh_test.write(str(x_i))\n",
    "        fh_test.write(\" \")\n",
    "\n",
    "    # write y to file\n",
    "    for y_i in range(0, 5, 1):\n",
    "        # if index == y_i:\n",
    "        fh_test.write(str(y[y_i]))\n",
    "        # else:\n",
    "        #    fh.write(\"0\")\n",
    "\n",
    "        if y_i != 4:\n",
    "            fh_test.write(\" \")\n",
    "\n",
    "    # fh.write(' y' + str(index))\n",
    "    fh_test.write(\"\\n\")\n",
    "    \n",
    "#generate 100 test samples.    \n",
    "for i in range(0, 20, 1):\n",
    "    for j in range(0, 5, 1):\n",
    "        calculate_test_y()\n",
    "\n",
    "fh_test.close()\n",
    "    \n",
    "df_test = pd.read_csv(\"test_data.txt\", header=None, delimiter=' ')\n",
    "\n",
    "df_test.columns = column_names\n",
    "\n",
    "df_test.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training dataset\n",
    "training_dataset = np.loadtxt(\"training_data.txt\", delimiter=' ')\n",
    "\n",
    "X_Train = training_dataset[:, 0:9]\n",
    "Y_Train = training_dataset[:, 9:14]\n",
    "\n",
    "#load test dataset\n",
    "test_dataset = np.loadtxt(\"test_data.txt\", delimiter=' ')\n",
    "\n",
    "X_Test = test_dataset[:, 0:9]\n",
    "Y_Test = test_dataset[:, 9:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating Model\n",
    "We have 9 inputs and 5 outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 69us/step\n",
      "100/100 [==============================] - 0s 18us/step\n",
      "Epoch_size: 500\n",
      "Learning Rate: 0.01\n",
      "Activation tanh\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.419446\n",
      "Test Loss: 0.382389 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 77us/step\n",
      "100/100 [==============================] - 0s 23us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.01\n",
      "Activation tanh\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.254067\n",
      "Test Loss: 0.247060 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 95us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "Epoch_size: 1500\n",
      "Learning Rate: 0.01\n",
      "Activation tanh\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.158591\n",
      "Test Loss: 0.141999 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 96us/step\n",
      "100/100 [==============================] - 0s 23us/step\n",
      "Epoch_size: 500\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.447771\n",
      "Test Loss: 0.460174 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 126us/step\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.210092\n",
      "Test Loss: 0.220436 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 128us/step\n",
      "100/100 [==============================] - 0s 22us/step\n",
      "Epoch_size: 1500\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.171035\n",
      "Test Loss: 0.164608 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_30 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 143us/step\n",
      "100/100 [==============================] - 0s 19us/step\n",
      "Epoch_size: 500\n",
      "Learning Rate: 0.5\n",
      "Activation tanh\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.392924\n",
      "Test Loss: 0.448674 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 156us/step\n",
      "100/100 [==============================] - 0s 21us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.5\n",
      "Activation tanh\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.343402\n",
      "Test Loss: 0.394330 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 183us/step\n",
      "100/100 [==============================] - 0s 22us/step\n",
      "Epoch_size: 1500\n",
      "Learning Rate: 0.5\n",
      "Activation tanh\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.264647\n",
      "Test Loss: 0.268282 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 199us/step\n",
      "100/100 [==============================] - 0s 22us/step\n",
      "Epoch_size: 500\n",
      "Learning Rate: 0.01\n",
      "Activation relu\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.497588\n",
      "Test Loss: 0.486522 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_50 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 270us/step\n",
      "100/100 [==============================] - 0s 37us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.01\n",
      "Activation relu\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.954687\n",
      "Test Loss: 0.896945 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_55 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 269us/step\n",
      "100/100 [==============================] - 0s 26us/step\n",
      "Epoch_size: 1500\n",
      "Learning Rate: 0.01\n",
      "Activation relu\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.245691\n",
      "Test Loss: 0.256565 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 256us/step\n",
      "100/100 [==============================] - 0s 23us/step\n",
      "Epoch_size: 500\n",
      "Learning Rate: 0.1\n",
      "Activation relu\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.433357\n",
      "Test Loss: 0.462636 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_65 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 273us/step\n",
      "100/100 [==============================] - 0s 25us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation relu\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.289235\n",
      "Test Loss: 0.296862 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 282us/step\n",
      "100/100 [==============================] - 0s 29us/step\n",
      "Epoch_size: 1500\n",
      "Learning Rate: 0.1\n",
      "Activation relu\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 1.100258\n",
      "Test Loss: 1.000623 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_75 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 302us/step\n",
      "100/100 [==============================] - 0s 24us/step\n",
      "Epoch_size: 500\n",
      "Learning Rate: 0.1\n",
      "Activation sigmoid\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.998015\n",
      "Test Loss: 0.922934 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_80 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 318us/step\n",
      "100/100 [==============================] - 0s 24us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation sigmoid\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.449912\n",
      "Test Loss: 0.453724 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_85 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 334us/step\n",
      "100/100 [==============================] - 0s 101us/step\n",
      "Epoch_size: 1500\n",
      "Learning Rate: 0.1\n",
      "Activation sigmoid\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.260341\n",
      "Test Loss: 0.274919 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_90 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 383us/step\n",
      "100/100 [==============================] - 0s 26us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.01\n",
      "Activation sigmoid\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 1.855052\n",
      "Test Loss: 1.611970 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_95 (Dense)             (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 4)                 40        \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 195\n",
      "Trainable params: 195\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 370us/step\n",
      "100/100 [==============================] - 0s 32us/step\n",
      "Epoch_size: 1500\n",
      "Learning Rate: 0.2\n",
      "Activation sigmoid\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.171550\n",
      "Test Loss: 0.186467 \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation\n",
    "\n",
    "#set different parameters here.\n",
    "def generate_and_train_model(X_Train,Y_Train,X_Test,Y_Test,activation,hidden_1,hidden_2,hidden_3,learning_rate,epoch_size):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(9, input_dim=9))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(hidden_1))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(hidden_2))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(hidden_3))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    sgd = optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "    model.fit(X_Train, Y_Train, epochs=epoch_size, verbose=0)\n",
    "\n",
    "    training_scores = model.evaluate(X_Train, Y_Train)\n",
    "\n",
    "    test_scores = model.evaluate(X_Test, Y_Test)\n",
    "\n",
    "    print(\"Epoch_size: \" + str(epoch_size))\n",
    "    print(\"Learning Rate: \" + str(learning_rate))\n",
    "    print(\"Activation \" + str(activation))\n",
    "    print(\"Hidden_1 \" + str(hidden_1))\n",
    "    print(\"Hidden_2 \" + str(hidden_2))\n",
    "    print(\"Hidden_3 \" + str(hidden_3))\n",
    "\n",
    "    print(\"Train Loss: %f\" % training_scores)\n",
    "    print(\"Test Loss: %f \" % test_scores)\n",
    "    \n",
    "    \n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.01, 500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.01, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.01, 1500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.1, 500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.1, 1500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.5, 500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.5, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.5, 1500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"relu\", 4, 4, 4, 0.01, 500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"relu\", 4, 4, 4, 0.01, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"relu\", 4, 4, 4, 0.01, 1500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"relu\", 4, 4, 4, 0.1, 500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"relu\", 4, 4, 4, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"relu\", 4, 4, 4, 0.1, 1500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"sigmoid\", 4, 4, 4, 0.1, 500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"sigmoid\", 4, 4, 4, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"sigmoid\", 4, 4, 4, 0.1, 1500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"sigmoid\", 4, 4, 4, 0.01, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"sigmoid\", 4, 4, 4, 0.2, 1500)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data Size | Input Node | Input Act | Dense-1 | Dense-1 Act | Dense-2 | Dense-2 Act | Dense-3 | Dense-3 Act | Output Node | Output Act | L.Rate | Epoch | Train Error | Test Error |\n",
    "|:---------:|:----------:|:---------:|:-------:|:-----------:|:-------:|:-----------:|:-------:|:-----------:|:-----------:|:----------:|:------:|:-----:|:-----------:|:----------:|\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.242384  |  0.296860  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  1500 |   0.126778  |  0.167803  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  2000 |   0.217331  |  0.260438  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.1  |  1000 |   0.218391  |  0.280169  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.1  |  1500 |   0.190859  |  0.242867  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.1  |  2000 |   0.179826  |  0.242151  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.5  |  1000 |   0.410062  |  0.473462  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.5  |  1500 |   0.569335  |  0.677881  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.5  |  2000 |   0.345615  |  0.403062  |\n",
    "|    600    |      9     |    relu   |    4    |     relu    |    4    |     relu    |    4    |     relu    |      5      |   linear   |  0.01  |  1000 |   1.822732  |  2.347571  |\n",
    "|    600    |      9     |    relu   |    4    |     relu    |    4    |     relu    |    4    |     relu    |      5      |   linear   |  0.01  |  1500 |   0.805988  |  0.992025  |\n",
    "|    600    |      9     |    relu   |    4    |     relu    |    4    |     relu    |    4    |     relu    |      5      |   linear   |  0.01  |  2000 |   0.462038  |  0.488292  |\n",
    "|    600    |      9     |    relu   |    4    |     tanh    |    4    |     relu    |    4    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.283931  |  0.325317  |\n",
    "|    600    |      9     |    relu   |    4    |     tanh    |    4    |     relu    |    4    |     tanh    |      5      |   linear   |  0.01  |  1500 |   0.397254  |  0.421426  |\n",
    "|    600    |      9     |    relu   |    4    |     tanh    |    4    |     relu    |    4    |     tanh    |      5      |   linear   |  0.01  |  2000 |   0.230768  |  0.269217  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding New Nodes to Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_100 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 6)                 60        \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 4)                 20        \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 223\n",
      "Trainable params: 223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 386us/step\n",
      "100/100 [==============================] - 0s 27us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 6\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.137321\n",
      "Test Loss: 0.149897 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_105 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 6)                 60        \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_109 (Dense)            (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 245\n",
      "Trainable params: 245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 424us/step\n",
      "100/100 [==============================] - 0s 25us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 6\n",
      "Hidden_2 6\n",
      "Hidden_3 4\n",
      "Train Loss: 0.157052\n",
      "Test Loss: 0.150626 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_110 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_111 (Dense)            (None, 6)                 60        \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_113 (Dense)            (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 5)                 35        \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 269\n",
      "Trainable params: 269\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 445us/step\n",
      "100/100 [==============================] - 0s 26us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 6\n",
      "Hidden_2 6\n",
      "Hidden_3 6\n",
      "Train Loss: 0.097890\n",
      "Test Loss: 0.115209 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_115 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_117 (Dense)            (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 6)                 42        \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_119 (Dense)            (None, 5)                 35        \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 301\n",
      "Trainable params: 301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 448us/step\n",
      "100/100 [==============================] - 0s 29us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 8\n",
      "Hidden_2 6\n",
      "Hidden_3 6\n",
      "Train Loss: 0.107035\n",
      "Test Loss: 0.112449 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_120 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_121 (Dense)            (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_123 (Dense)            (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 5)                 35        \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 331\n",
      "Trainable params: 331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 488us/step\n",
      "100/100 [==============================] - 0s 35us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 8\n",
      "Hidden_2 8\n",
      "Hidden_3 6\n",
      "Train Loss: 0.101614\n",
      "Test Loss: 0.107846 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_125 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_127 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_129 (Dense)            (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 359\n",
      "Trainable params: 359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 487us/step\n",
      "100/100 [==============================] - 0s 28us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 8\n",
      "Hidden_2 8\n",
      "Hidden_3 8\n",
      "Train Loss: 0.071286\n",
      "Test Loss: 0.080146 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_130 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_131 (Dense)            (None, 10)                100       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 395\n",
      "Trainable params: 395\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 526us/step\n",
      "100/100 [==============================] - 0s 36us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 10\n",
      "Hidden_2 8\n",
      "Hidden_3 8\n",
      "Train Loss: 0.056731\n",
      "Test Loss: 0.057640 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_135 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_136 (Dense)            (None, 10)                100       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_137 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_138 (Dense)            (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_139 (Dense)            (None, 5)                 45        \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 433\n",
      "Trainable params: 433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 544us/step\n",
      "100/100 [==============================] - 0s 78us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 10\n",
      "Hidden_2 10\n",
      "Hidden_3 8\n",
      "Train Loss: 0.071971\n",
      "Test Loss: 0.083382 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_140 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_141 (Dense)            (None, 10)                100       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_142 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_144 (Dense)            (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 465\n",
      "Trainable params: 465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 551us/step\n",
      "100/100 [==============================] - 0s 29us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 10\n",
      "Hidden_2 10\n",
      "Hidden_3 10\n",
      "Train Loss: 0.076491\n",
      "Test Loss: 0.080574 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_145 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 12)                120       \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_148 (Dense)            (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 505\n",
      "Trainable params: 505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 664us/step\n",
      "100/100 [==============================] - 0s 28us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 12\n",
      "Hidden_2 10\n",
      "Hidden_3 10\n",
      "Train Loss: 0.042226\n",
      "Test Loss: 0.053065 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_150 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 12)                120       \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 551\n",
      "Trainable params: 551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 590us/step\n",
      "100/100 [==============================] - 0s 35us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 12\n",
      "Hidden_2 12\n",
      "Hidden_3 10\n",
      "Train Loss: 0.040507\n",
      "Test Loss: 0.054493 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_155 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 12)                120       \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 5)                 65        \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 587\n",
      "Trainable params: 587\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 618us/step\n",
      "100/100 [==============================] - 0s 26us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 12\n",
      "Hidden_2 12\n",
      "Hidden_3 12\n",
      "Train Loss: 0.025883\n",
      "Test Loss: 0.043068 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_160 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 14)                140       \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 12)                180       \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 12)                156       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 5)                 65        \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 631\n",
      "Trainable params: 631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 628us/step\n",
      "100/100 [==============================] - 0s 36us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 14\n",
      "Hidden_2 12\n",
      "Hidden_3 12\n",
      "Train Loss: 0.080733\n",
      "Test Loss: 0.094413 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_165 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 14)                140       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 14)                210       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 12)                180       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 12)                0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 5)                 65        \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 685\n",
      "Trainable params: 685\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 642us/step\n",
      "100/100 [==============================] - 0s 30us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 14\n",
      "Hidden_2 14\n",
      "Hidden_3 12\n",
      "Train Loss: 0.063983\n",
      "Test Loss: 0.082955 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_170 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 14)                140       \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 14)                210       \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 14)                210       \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 5)                 75        \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 725\n",
      "Trainable params: 725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 668us/step\n",
      "100/100 [==============================] - 0s 26us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 14\n",
      "Hidden_2 14\n",
      "Hidden_3 14\n",
      "Train Loss: 0.051212\n",
      "Test Loss: 0.076704 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_175 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 16)                160       \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 14)                238       \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 14)                210       \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 5)                 75        \n",
      "_________________________________________________________________\n",
      "activation_179 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 773\n",
      "Trainable params: 773\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 685us/step\n",
      "100/100 [==============================] - 0s 30us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 16\n",
      "Hidden_2 14\n",
      "Hidden_3 14\n",
      "Train Loss: 0.021930\n",
      "Test Loss: 0.030710 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_180 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_180 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 16)                160       \n",
      "_________________________________________________________________\n",
      "activation_181 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_182 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_183 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 5)                 85        \n",
      "_________________________________________________________________\n",
      "activation_184 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 879\n",
      "Trainable params: 879\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 708us/step\n",
      "100/100 [==============================] - 0s 30us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 16\n",
      "Hidden_2 16\n",
      "Hidden_3 16\n",
      "Train Loss: 0.017481\n",
      "Test Loss: 0.033158 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_185 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_185 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 18)                180       \n",
      "_________________________________________________________________\n",
      "activation_186 (Activation)  (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 16)                304       \n",
      "_________________________________________________________________\n",
      "activation_187 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_188 (Activation)  (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 5)                 85        \n",
      "_________________________________________________________________\n",
      "activation_189 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 931\n",
      "Trainable params: 931\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 738us/step\n",
      "100/100 [==============================] - 0s 45us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 18\n",
      "Hidden_2 16\n",
      "Hidden_3 16\n",
      "Train Loss: 0.019709\n",
      "Test Loss: 0.029369 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_190 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_190 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 18)                180       \n",
      "_________________________________________________________________\n",
      "activation_191 (Activation)  (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "activation_192 (Activation)  (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "activation_193 (Activation)  (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 5)                 95        \n",
      "_________________________________________________________________\n",
      "activation_194 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,049\n",
      "Trainable params: 1,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 764us/step\n",
      "100/100 [==============================] - 0s 35us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 18\n",
      "Hidden_2 18\n",
      "Hidden_3 18\n",
      "Train Loss: 0.024548\n",
      "Test Loss: 0.040175 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_195 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_195 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 20)                200       \n",
      "_________________________________________________________________\n",
      "activation_196 (Activation)  (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 18)                378       \n",
      "_________________________________________________________________\n",
      "activation_197 (Activation)  (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 18)                342       \n",
      "_________________________________________________________________\n",
      "activation_198 (Activation)  (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 5)                 95        \n",
      "_________________________________________________________________\n",
      "activation_199 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,105\n",
      "Trainable params: 1,105\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600/600 [==============================] - 0s 776us/step\n",
      "100/100 [==============================] - 0s 40us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 20\n",
      "Hidden_2 18\n",
      "Hidden_3 18\n",
      "Train Loss: 0.012109\n",
      "Test Loss: 0.022863 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_200 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_200 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 20)                200       \n",
      "_________________________________________________________________\n",
      "activation_201 (Activation)  (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "activation_202 (Activation)  (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 18)                378       \n",
      "_________________________________________________________________\n",
      "activation_203 (Activation)  (None, 18)                0         \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 5)                 95        \n",
      "_________________________________________________________________\n",
      "activation_204 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,183\n",
      "Trainable params: 1,183\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 803us/step\n",
      "100/100 [==============================] - 0s 33us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 20\n",
      "Hidden_2 20\n",
      "Hidden_3 18\n",
      "Train Loss: 0.065272\n",
      "Test Loss: 0.078477 \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_205 (Dense)            (None, 9)                 90        \n",
      "_________________________________________________________________\n",
      "activation_205 (Activation)  (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 20)                200       \n",
      "_________________________________________________________________\n",
      "activation_206 (Activation)  (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "activation_207 (Activation)  (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "activation_208 (Activation)  (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 5)                 105       \n",
      "_________________________________________________________________\n",
      "activation_209 (Activation)  (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 1,235\n",
      "Trainable params: 1,235\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "600/600 [==============================] - 0s 817us/step\n",
      "100/100 [==============================] - 0s 50us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 20\n",
      "Hidden_2 20\n",
      "Hidden_3 20\n",
      "Train Loss: 0.012805\n",
      "Test Loss: 0.027987 \n"
     ]
    }
   ],
   "source": [
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 6, 4, 4, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 6, 6, 4, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 6, 6, 6, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 8, 6, 6, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 8, 8, 6, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 8, 8, 8, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 10, 8, 8, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 10, 10, 8, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 10, 10, 10, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 12, 10, 10, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 12, 12, 10, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 12, 12, 12, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 14, 12, 12, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 14, 14, 12, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 14, 14, 14, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 16, 14, 14, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 16, 16, 16, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 18, 16, 16, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 18, 18, 18, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 20, 18, 18, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 20, 20, 18, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 20, 20, 20, 0.1, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have add 2 node every time and the result is:\n",
    "\n",
    "| Data Size | Input Node | Input Act | Dense-1 | Dense-1 Act | Dense-2 | Dense-2 Act | Dense-3 | Dense-3 Act | Output Node | Output Act | L.Rate | Epoch | Train Error | Test Error |\n",
    "|:---------:|:----------:|:---------:|:-------:|:-----------:|:-------:|:-----------:|:-------:|:-----------:|:-----------:|:----------:|:------:|:-----:|:-----------:|:----------:|\n",
    "|    600    |      9     |    tanh   |    6    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.230664  |  0.284872  |\n",
    "|    600    |      9     |    tanh   |    6    |     tanh    |    6    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.107739  |  0.147939  |\n",
    "|    600    |      9     |    tanh   |    6    |     tanh    |    6    |     tanh    |    6    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.106117  |  0.138951  |\n",
    "|    625    |      9     |    tanh   |    6    |     tanh    |    6    |     tanh    |    6    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.100039  |  0.105181  |\n",
    "|    600    |      9     |    tanh   |    8    |     tanh    |    6    |     tanh    |    6    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.103422  |  0.135032  |\n",
    "|    600    |      9     |    tanh   |    8    |     tanh    |    8    |     tanh    |    6    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.078349  |  0.112605  |\n",
    "|    600    |      9     |    tanh   |    8    |     tanh    |    8    |     tanh    |    8    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.061360  |  0.086895  |\n",
    "|    600    |      9     |    tanh   |    10   |     tanh    |    8    |     tanh    |    8    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.214529  |  0.275568  |\n",
    "|    600    |      9     |    tanh   |    10   |     tanh    |    10   |     tanh    |    8    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.066961  |  0.108347  |\n",
    "|    600    |      9     |    tanh   |    10   |     tanh    |    10   |     tanh    |    10   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.041627  |  0.073066  |\n",
    "|    600    |      9     |    tanh   |    12   |     tanh    |    10   |     tanh    |    10   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.038032  |  0.060367  |\n",
    "|    600    |      9     |    tanh   |    12   |     tanh    |    12   |     tanh    |    10   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.042953  |  0.079595  |\n",
    "|    600    |      9     |    tanh   |    12   |     tanh    |    12   |     tanh    |    12   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.034023  |  0.069341  |\n",
    "|    600    |      9     |    tanh   |    14   |     tanh    |    12   |     tanh    |    12   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.028721  |  0.051455  |\n",
    "|    600    |      9     |    tanh   |    14   |     tanh    |    14   |     tanh    |    12   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.029594  |  0.058277  |\n",
    "|    600    |      9     |    tanh   |    14   |     tanh    |    14   |     tanh    |    14   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.055583  |  0.075554  |\n",
    "|    600    |      9     |    tanh   |    16   |     tanh    |    14   |     tanh    |    14   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.030893  |  0.048610  |\n",
    "|    600    |      9     |    tanh   |    16   |     tanh    |    16   |     tanh    |    16   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.025738  |  0.061128  |\n",
    "|    600    |      9     |    tanh   |    18   |     tanh    |    16   |     tanh    |    16   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.031345  |  0.062981  |\n",
    "|    600    |      9     |    tanh   |    18   |     tanh    |    18   |     tanh    |    18   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.048698  |  0.083283  |\n",
    "|    600    |      9     |    tanh   |    20   |     tanh    |    18   |     tanh    |    18   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.028212  |  0.048121  |\n",
    "|    600    |      9     |    tanh   |    20   |     tanh    |    20   |     tanh    |    18   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.015122  |  0.036735  |\n",
    "|    600    |      9     |    tanh   |    20   |     tanh    |    20   |     tanh    |    20   |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.023472  |  0.049407  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "For my data optimal parameters are:\n",
    "\n",
    "Activation: tanh, epoch: 1000\n",
    "\n",
    "After 16 node test error increased and train error dropped. We must stop before that. Because models variance is lower.\n",
    "\n",
    "According to result 16 ,16, 16 layers training error decreased to 0.03 to 0.02 but test error is increased 0.04 to 0.06\n",
    "\n",
    "Bigger learning rates are increasing error rates both training and test values.\n",
    "\n",
    "generating data between (0,1) giving more accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Digit Recognition using CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f96cb36ea58>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "mnist_digits = tf.keras.datasets.mnist\n",
    "\n",
    "\n",
    "#mnist_digits.load_data()\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist_digits.load_data()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# Only use this if using iPython\n",
    "image_index = 11 \n",
    "# You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading AlexNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization, Flatten, Dropout\n",
    "\n",
    "\n",
    "def create_and_train_mnist_alexnet(learning_rate, activation):\n",
    "    mnist_digits = tf.keras.datasets.mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist_digits.load_data()\n",
    "    img_shape = (28, 28)\n",
    "\n",
    "    # print(x_train[0])\n",
    "    print(x_train[0].shape)\n",
    "    print(x_train.shape)\n",
    "\n",
    "    x_train = np.expand_dims(x_train, 3)\n",
    "    print(x_train.shape)\n",
    "\n",
    "    y_train = np.expand_dims(y_train, 3)\n",
    "    print(y_train[0].shape)\n",
    "\n",
    "    # x_train = np.swapaxes(x_train,1,3)\n",
    "    # print(x_train[0].shape)\n",
    "\n",
    "    l2_reg = 0\n",
    "    n_classes = 10\n",
    "    alexnet = Sequential()\n",
    "\n",
    "    # Layer 1\n",
    "    alexnet.add(Conv2D(96, (11, 11), input_shape=x_train[0].shape,\n",
    "                       padding='same', kernel_regularizer=l2(l2_reg)))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 2\n",
    "    alexnet.add(Conv2D(256, (5, 5), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 3\n",
    "    alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    alexnet.add(Conv2D(384, (3, 3), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 4\n",
    "    alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    alexnet.add(Conv2D(384, (3, 3), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "\n",
    "    # Layer 5\n",
    "    alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    alexnet.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 6\n",
    "    alexnet.add(Flatten())\n",
    "    alexnet.add(Dense(4096))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(Dropout(0.5))\n",
    "\n",
    "    # Layer 7\n",
    "    alexnet.add(Dense(4096))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(Dropout(0.5))\n",
    "\n",
    "    # Layer 8\n",
    "    alexnet.add(Dense(n_classes))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation('softmax'))\n",
    "\n",
    "    alexnet.summary()\n",
    "\n",
    "    adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "    # (4) Compile\n",
    "    alexnet.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    # (5) Train\n",
    "    alexnet.fit(x_train, y_train, batch_size=2048, epochs=1, validation_split=0.2, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training The Mnist Data with AlexNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codegenius/DevOps/VirtualEnvs/deepEnv/lib/python3.5/site-packages/ipykernel_launcher.py:22: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 96)        11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_210 (Activation)  (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_211 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 9, 9, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_212 (Activation)  (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 6, 6, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_213 (Activation)  (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_214 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_215 (Activation)  (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_216 (Activation)  (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_217 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 37,365,874\n",
      "Trainable params: 37,346,718\n",
      "Non-trainable params: 19,156\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/1\n",
      "48000/48000 [==============================] - 1661s 35ms/step - loss: 1.2084 - acc: 0.6586 - val_loss: 14.5117 - val_acc: 0.0997\n"
     ]
    }
   ],
   "source": [
    "create_and_train_mnist_alexnet(0.01, 'relu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Increasing Dense Layer Parameter Size "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization, Flatten, Dropout\n",
    "\n",
    "\n",
    "def create_and_train_mnist_alexnet_different_dense(learning_rate, activation, dense_layer_size):\n",
    "    mnist_digits = tf.keras.datasets.mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist_digits.load_data()\n",
    "    img_shape = (28, 28)\n",
    "\n",
    "    # print(x_train[0])\n",
    "    print(x_train[0].shape)\n",
    "    print(x_train.shape)\n",
    "\n",
    "    x_train = np.expand_dims(x_train, 3)\n",
    "    print(x_train.shape)\n",
    "\n",
    "    y_train = np.expand_dims(y_train, 3)\n",
    "    print(y_train[0].shape)\n",
    "\n",
    "    # x_train = np.swapaxes(x_train,1,3)\n",
    "    # print(x_train[0].shape)\n",
    "\n",
    "    l2_reg = 0\n",
    "    n_classes = 10\n",
    "    alexnet = Sequential()\n",
    "\n",
    "    # Layer 1\n",
    "    alexnet.add(Conv2D(96, (11, 11), input_shape=x_train[0].shape,\n",
    "                       padding='same', kernel_regularizer=l2(l2_reg)))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 2\n",
    "    alexnet.add(Conv2D(256, (5, 5), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 3\n",
    "    alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    alexnet.add(Conv2D(384, (3, 3), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 4\n",
    "    alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    alexnet.add(Conv2D(384, (3, 3), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "\n",
    "    # Layer 5\n",
    "    alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    alexnet.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 6\n",
    "    alexnet.add(Flatten())\n",
    "    alexnet.add(Dense(dense_layer_size))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(Dropout(0.5))\n",
    "\n",
    "    # Layer 7\n",
    "    alexnet.add(Dense(dense_layer_size))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(Dropout(0.5))\n",
    "\n",
    "    # Layer 8\n",
    "    alexnet.add(Dense(n_classes))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation('softmax'))\n",
    "\n",
    "    alexnet.summary()\n",
    "\n",
    "    adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "    # (4) Compile\n",
    "    alexnet.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    # (5) Train\n",
    "    #alexnet.fit(x_train, y_train, batch_size=2048, epochs=1, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Training With Different Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codegenius/DevOps/VirtualEnvs/deepEnv/lib/python3.5/site-packages/ipykernel_launcher.py:22: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 28, 28, 96)        11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 28, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_218 (Activation)  (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 14, 14, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_219 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 9, 9, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_220 (Activation)  (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_221 (Activation)  (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_222 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 4596)              18829812  \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 4596)              18384     \n",
      "_________________________________________________________________\n",
      "activation_223 (Activation)  (None, 4596)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4596)              0         \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 4596)              21127812  \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 4596)              18384     \n",
      "_________________________________________________________________\n",
      "activation_224 (Activation)  (None, 4596)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4596)              0         \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 10)                45970     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_225 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 43,769,874\n",
      "Trainable params: 43,748,718\n",
      "Non-trainable params: 21,156\n",
      "_________________________________________________________________\n",
      "(28, 28)\n",
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "(1,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 28, 28, 96)        11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 28, 28, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_226 (Activation)  (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_227 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 9, 9, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_228 (Activation)  (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 6, 6, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_229 (Activation)  (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 8, 8, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_230 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 5096)              20878312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 5096)              20384     \n",
      "_________________________________________________________________\n",
      "activation_231 (Activation)  (None, 5096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5096)              0         \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 5096)              25974312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 5096)              20384     \n",
      "_________________________________________________________________\n",
      "activation_232 (Activation)  (None, 5096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5096)              0         \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 10)                50970     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_233 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 50,673,874\n",
      "Trainable params: 50,650,718\n",
      "Non-trainable params: 23,156\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "(1,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 28, 28, 96)        11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 28, 28, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_234 (Activation)  (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 14, 14, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_235 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 9, 9, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_236 (Activation)  (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 6, 6, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_237 (Activation)  (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 8, 8, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_238 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 5596)              22926812  \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 5596)              22384     \n",
      "_________________________________________________________________\n",
      "activation_239 (Activation)  (None, 5596)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 5596)              0         \n",
      "_________________________________________________________________\n",
      "dense_220 (Dense)            (None, 5596)              31320812  \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 5596)              22384     \n",
      "_________________________________________________________________\n",
      "activation_240 (Activation)  (None, 5596)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 5596)              0         \n",
      "_________________________________________________________________\n",
      "dense_221 (Dense)            (None, 10)                55970     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_241 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 58,077,874\n",
      "Trainable params: 58,052,718\n",
      "Non-trainable params: 25,156\n",
      "_________________________________________________________________\n",
      "(28, 28)\n",
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "(1,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 96)        11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 28, 28, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_242 (Activation)  (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 14, 14, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_243 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 9, 9, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_244 (Activation)  (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 6, 6, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_245 (Activation)  (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPaddi (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 8, 8, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_246 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_222 (Dense)            (None, 4596)              18829812  \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 4596)              18384     \n",
      "_________________________________________________________________\n",
      "activation_247 (Activation)  (None, 4596)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 4596)              0         \n",
      "_________________________________________________________________\n",
      "dense_223 (Dense)            (None, 4596)              21127812  \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 4596)              18384     \n",
      "_________________________________________________________________\n",
      "activation_248 (Activation)  (None, 4596)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4596)              0         \n",
      "_________________________________________________________________\n",
      "dense_224 (Dense)            (None, 10)                45970     \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_249 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 43,769,874\n",
      "Trainable params: 43,748,718\n",
      "Non-trainable params: 21,156\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "(1,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 96)        11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 28, 28, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_250 (Activation)  (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 14, 14, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_251 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPaddi (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 9, 9, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_252 (Activation)  (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPaddi (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 6, 6, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_253 (Activation)  (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPaddi (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 8, 8, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_254 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_225 (Dense)            (None, 5096)              20878312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 5096)              20384     \n",
      "_________________________________________________________________\n",
      "activation_255 (Activation)  (None, 5096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 5096)              0         \n",
      "_________________________________________________________________\n",
      "dense_226 (Dense)            (None, 5096)              25974312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 5096)              20384     \n",
      "_________________________________________________________________\n",
      "activation_256 (Activation)  (None, 5096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 5096)              0         \n",
      "_________________________________________________________________\n",
      "dense_227 (Dense)            (None, 10)                50970     \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_257 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 50,673,874\n",
      "Trainable params: 50,650,718\n",
      "Non-trainable params: 23,156\n",
      "_________________________________________________________________\n",
      "(28, 28)\n",
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "(1,)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_30 (Conv2D)           (None, 28, 28, 96)        11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 28, 28, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_258 (Activation)  (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 14, 14, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_259 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPaddi (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 9, 9, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_260 (Activation)  (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 4, 4, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPaddi (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 6, 6, 384)         1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 6, 6, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_261 (Activation)  (None, 6, 6, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPaddi (None, 8, 8, 384)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 8, 8, 256)         884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_262 (Activation)  (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_228 (Dense)            (None, 5596)              22926812  \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 5596)              22384     \n",
      "_________________________________________________________________\n",
      "activation_263 (Activation)  (None, 5596)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 5596)              0         \n",
      "_________________________________________________________________\n",
      "dense_229 (Dense)            (None, 5596)              31320812  \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 5596)              22384     \n",
      "_________________________________________________________________\n",
      "activation_264 (Activation)  (None, 5596)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 5596)              0         \n",
      "_________________________________________________________________\n",
      "dense_230 (Dense)            (None, 10)                55970     \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_265 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 58,077,874\n",
      "Trainable params: 58,052,718\n",
      "Non-trainable params: 25,156\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_and_train_mnist_alexnet_different_dense(0.1, 'relu', 4596)\n",
    "create_and_train_mnist_alexnet_different_dense(0.1, 'relu', 5096)\n",
    "create_and_train_mnist_alexnet_different_dense(0.1, 'relu', 5596)\n",
    "\n",
    "create_and_train_mnist_alexnet_different_dense(0.1, 'tanh', 4596)\n",
    "create_and_train_mnist_alexnet_different_dense(0.1, 'tanh', 5096)\n",
    "create_and_train_mnist_alexnet_different_dense(0.1, 'tanh', 5596)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Removing Third Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization, Flatten, Dropout\n",
    "\n",
    "\n",
    "def create_and_train_mnist_alexnet_different_dense(learning_rate, activation, dense_layer_size):\n",
    "    mnist_digits = tf.keras.datasets.mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist_digits.load_data()\n",
    "    img_shape = (28, 28)\n",
    "\n",
    "    # print(x_train[0])\n",
    "    print(x_train[0].shape)\n",
    "    print(x_train.shape)\n",
    "\n",
    "    x_train = np.expand_dims(x_train, 3)\n",
    "    print(x_train.shape)\n",
    "\n",
    "    y_train = np.expand_dims(y_train, 3)\n",
    "    print(y_train[0].shape)\n",
    "\n",
    "    # x_train = np.swapaxes(x_train,1,3)\n",
    "    # print(x_train[0].shape)\n",
    "\n",
    "    l2_reg = 0\n",
    "    n_classes = 10\n",
    "    alexnet = Sequential()\n",
    "\n",
    "    # Layer 1\n",
    "    alexnet.add(Conv2D(96, (11, 11), input_shape=x_train[0].shape,\n",
    "                       padding='same', kernel_regularizer=l2(l2_reg)))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 2\n",
    "    alexnet.add(Conv2D(256, (5, 5), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    #REMOVE\n",
    "    # Layer 3\n",
    "    #alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    #alexnet.add(Conv2D(384, (3, 3), padding='same'))\n",
    "    #alexnet.add(BatchNormalization())\n",
    "    #alexnet.add(Activation(activation))\n",
    "    #alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 4\n",
    "    alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    alexnet.add(Conv2D(384, (3, 3), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "\n",
    "    # Layer 5\n",
    "    alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    alexnet.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 6\n",
    "    alexnet.add(Flatten())\n",
    "    alexnet.add(Dense(dense_layer_size))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(Dropout(0.5))\n",
    "\n",
    "    # Layer 7\n",
    "    alexnet.add(Dense(dense_layer_size))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(Dropout(0.5))\n",
    "\n",
    "    # Layer 8\n",
    "    alexnet.add(Dense(n_classes))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation('softmax'))\n",
    "\n",
    "    alexnet.summary()\n",
    "\n",
    "    adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "    # (4) Compile\n",
    "    alexnet.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    # (5) Train\n",
    "    #alexnet.fit(x_train, y_train, batch_size=2048, epochs=1, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codegenius/DevOps/VirtualEnvs/deepEnv/lib/python3.5/site-packages/ipykernel_launcher.py:22: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_42 (Conv2D)           (None, 28, 28, 96)        11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 28, 28, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_279 (Activation)  (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 14, 14, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_280 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPaddi (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 9, 9, 384)         885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 9, 9, 384)         1536      \n",
      "_________________________________________________________________\n",
      "activation_281 (Activation)  (None, 9, 9, 384)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPaddi (None, 11, 11, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 11, 11, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 11, 11, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_282 (Activation)  (None, 11, 11, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 5096)              32619496  \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 5096)              20384     \n",
      "_________________________________________________________________\n",
      "activation_283 (Activation)  (None, 5096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 5096)              0         \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 5096)              25974312  \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 5096)              20384     \n",
      "_________________________________________________________________\n",
      "activation_284 (Activation)  (None, 5096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 5096)              0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 10)                50970     \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_285 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 61,086,034\n",
      "Trainable params: 61,063,646\n",
      "Non-trainable params: 22,388\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_and_train_mnist_alexnet_different_dense(0.1, 'relu', 5096)\n",
    "create_and_train_mnist_alexnet_different_dense(0.1, 'tanh', 5096)\n",
    "create_and_train_mnist_alexnet_different_dense(0.01, 'relu', 5096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Removing Third and Fourth Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization, Flatten, Dropout\n",
    "\n",
    "\n",
    "def create_and_train_mnist_alexnet_different_dense(learning_rate, activation, dense_layer_size):\n",
    "    mnist_digits = tf.keras.datasets.mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist_digits.load_data()\n",
    "    img_shape = (28, 28)\n",
    "\n",
    "    # print(x_train[0])\n",
    "    print(x_train[0].shape)\n",
    "    print(x_train.shape)\n",
    "\n",
    "    x_train = np.expand_dims(x_train, 3)\n",
    "    print(x_train.shape)\n",
    "\n",
    "    y_train = np.expand_dims(y_train, 3)\n",
    "    print(y_train[0].shape)\n",
    "\n",
    "    # x_train = np.swapaxes(x_train,1,3)\n",
    "    # print(x_train[0].shape)\n",
    "\n",
    "    l2_reg = 0\n",
    "    n_classes = 10\n",
    "    alexnet = Sequential()\n",
    "\n",
    "    # Layer 1\n",
    "    alexnet.add(Conv2D(96, (11, 11), input_shape=x_train[0].shape,\n",
    "                       padding='same', kernel_regularizer=l2(l2_reg)))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 2\n",
    "    alexnet.add(Conv2D(256, (5, 5), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    #REMOVE\n",
    "    # Layer 3\n",
    "    #alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    #alexnet.add(Conv2D(384, (3, 3), padding='same'))\n",
    "    #alexnet.add(BatchNormalization())\n",
    "    #alexnet.add(Activation(activation))\n",
    "    #alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 4\n",
    "    #alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    #alexnet.add(Conv2D(384, (3, 3), padding='same'))\n",
    "    #alexnet.add(BatchNormalization())\n",
    "    #alexnet.add(Activation(activation))\n",
    "\n",
    "    # Layer 5\n",
    "    alexnet.add(ZeroPadding2D((1, 1)))\n",
    "    alexnet.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Layer 6\n",
    "    alexnet.add(Flatten())\n",
    "    alexnet.add(Dense(dense_layer_size))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(Dropout(0.5))\n",
    "\n",
    "    # Layer 7\n",
    "    alexnet.add(Dense(dense_layer_size))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation(activation))\n",
    "    alexnet.add(Dropout(0.5))\n",
    "\n",
    "    # Layer 8\n",
    "    alexnet.add(Dense(n_classes))\n",
    "    alexnet.add(BatchNormalization())\n",
    "    alexnet.add(Activation('softmax'))\n",
    "\n",
    "    alexnet.summary()\n",
    "\n",
    "    adam = optimizers.Adam(lr=learning_rate, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "    # (4) Compile\n",
    "    alexnet.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    # (5) Train\n",
    "    #alexnet.fit(x_train, y_train, batch_size=2048, epochs=1, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n",
      "(60000, 28, 28)\n",
      "(60000, 28, 28, 1)\n",
      "(1,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codegenius/DevOps/VirtualEnvs/deepEnv/lib/python3.5/site-packages/ipykernel_launcher.py:22: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_39 (Conv2D)           (None, 28, 28, 96)        11712     \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 28, 28, 96)        384       \n",
      "_________________________________________________________________\n",
      "activation_273 (Activation)  (None, 28, 28, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 14, 14, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 14, 14, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "activation_274 (Activation)  (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPaddi (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 9, 9, 256)         590080    \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 9, 9, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_275 (Activation)  (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 5596)              22926812  \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 5596)              22384     \n",
      "_________________________________________________________________\n",
      "activation_276 (Activation)  (None, 5596)              0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 5596)              0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 5596)              31320812  \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 5596)              22384     \n",
      "_________________________________________________________________\n",
      "activation_277 (Activation)  (None, 5596)              0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 5596)              0         \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 10)                55970     \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_278 (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 55,567,282\n",
      "Trainable params: 55,543,662\n",
      "Non-trainable params: 23,620\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_and_train_mnist_alexnet_different_dense(0.1, 'relu', 5596)\n",
    "create_and_train_mnist_alexnet_different_dense(0.1, 'tanh', 5596)\n",
    "create_and_train_mnist_alexnet_different_dense(0.01, 'relu', 5596)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Training the AlexNET on my computer with cpu is taking too time. That's why I choose epoch as just 1. With default parameters, it took 15mins~\n",
    "\n",
    "\n",
    "I couldn't fill all the matrix but I implemented the models. Here is the results:\n",
    "\n",
    "| Training Data Size | Test Data Size |           Input Node          | Hidden Activation | Dense-1 | Dense-2 | Param Size | Epoch | L.Rate | Train Error | Train Accuracy | Test Error | Test Accuracy |\n",
    "|:------------------:|:--------------:|:-----------------------------:|:-----------------:|:-------:|:-------:|:----------:|:-----:|:------:|:-----------:|:--------------:|:----------:|:-------------:|\n",
    "|        48000       |      12000     |              784              |        relu       |   4096  |   4096  | 37,365,874 |   1   |  0.01  |    1.2084   |     0.6586     |   14.5117  |     0.0997    |\n",
    "|        48000       |      12000     |              784              |        relu       |   4096  |   4096  | 37,365,874 |   1   |   0.1  |    1.6354   |     0.4397     |   13.4288  |     0.1667    |\n",
    "|        48000       |      12000     |              784              |        relu       |   4096  |   4096  | 37,365,874 |   1   |   0.2  |      x      |        x       |      x     |       x       |\n",
    "|        48000       |      12000     |              784              |        relu       |   4596  |   4596  | 43,769,874 |   1   |   0.1  |      x      |        x       |      x     |       x       |\n",
    "|        48000       |      12000     |              784              |        relu       |   5096  |   5096  | 50,673,874 |   1   |   0.1  |      x      |        x       |      x     |       x       |\n",
    "|        48000       |      12000     |              784              |        relu       |   5596  |   5596  | 58,077,874 |   1   |   0.1  |      x      |        x       |      x     |       x       |\n",
    "|        48000       |      12000     |              784              |        tanh       |   4596  |   4596  | 43,769,874 |   1   |   0.1  |      x      |        x       |      x     |       x       |\n",
    "|        48000       |      12000     |              784              |        tanh       |   5096  |   5096  | 50,673,874 |   1   |   0.1  |      x      |        x       |      x     |       x       |\n",
    "|        48000       |      12000     |              784              |        tanh       |   5596  |   5596  | 58,077,874 |   1   |   0.1  |      x      |        x       |      x     |       x       |\n",
    "|        48000       |      12000     |     784 - 3. Layer Removed    |        relu       |   5096  |   5096  | 61,086,034 |   1   |   0.1  |      x      |        x       |      x     |       x       |\n",
    "|        48000       |      12000     | 784 - 3. and 4. Layer Removed |        relu       |   5596  |   5596  | 55,567,282 |   1   |   0.1  |      x      |        x       |      x     |       x       |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "I must use gpu for faster results. As soon as possible I'll buy an Nvidia Gpu. For using mnist data on alexnet we must change the channels and dimensions. AlexNet is (227,227,1) for mnist it is (28,28,1).\n",
    "\n",
    "Using 0.01 as learning rate given better result than 0.1.\n",
    "\n",
    "I will try the matrix's other rows after sending this report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
