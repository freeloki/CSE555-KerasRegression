{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Model a Deep Feed Forward Network for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Generating Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.949688</td>\n",
       "      <td>0.775597</td>\n",
       "      <td>0.913830</td>\n",
       "      <td>0.013655</td>\n",
       "      <td>0.560499</td>\n",
       "      <td>0.360725</td>\n",
       "      <td>0.943691</td>\n",
       "      <td>0.833470</td>\n",
       "      <td>0.484945</td>\n",
       "      <td>-3.641941</td>\n",
       "      <td>-0.641199</td>\n",
       "      <td>-1.824330</td>\n",
       "      <td>-6.095105</td>\n",
       "      <td>-0.794640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045952</td>\n",
       "      <td>0.027912</td>\n",
       "      <td>0.061524</td>\n",
       "      <td>0.763515</td>\n",
       "      <td>0.304402</td>\n",
       "      <td>0.387798</td>\n",
       "      <td>0.660480</td>\n",
       "      <td>0.216121</td>\n",
       "      <td>0.160511</td>\n",
       "      <td>0.672789</td>\n",
       "      <td>0.681849</td>\n",
       "      <td>-2.240863</td>\n",
       "      <td>-0.620841</td>\n",
       "      <td>-2.184313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.247389</td>\n",
       "      <td>0.477492</td>\n",
       "      <td>0.179739</td>\n",
       "      <td>0.722179</td>\n",
       "      <td>0.864501</td>\n",
       "      <td>0.384944</td>\n",
       "      <td>0.435235</td>\n",
       "      <td>0.607522</td>\n",
       "      <td>0.549980</td>\n",
       "      <td>1.831997</td>\n",
       "      <td>0.664697</td>\n",
       "      <td>-2.806331</td>\n",
       "      <td>-2.496279</td>\n",
       "      <td>-2.345635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060205</td>\n",
       "      <td>0.668670</td>\n",
       "      <td>0.793216</td>\n",
       "      <td>0.888407</td>\n",
       "      <td>0.549063</td>\n",
       "      <td>0.686823</td>\n",
       "      <td>0.242603</td>\n",
       "      <td>0.949293</td>\n",
       "      <td>0.024834</td>\n",
       "      <td>1.152319</td>\n",
       "      <td>0.949221</td>\n",
       "      <td>-1.641698</td>\n",
       "      <td>-3.124831</td>\n",
       "      <td>-4.091910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.827269</td>\n",
       "      <td>0.506180</td>\n",
       "      <td>0.293190</td>\n",
       "      <td>0.998661</td>\n",
       "      <td>0.913623</td>\n",
       "      <td>0.141839</td>\n",
       "      <td>0.339410</td>\n",
       "      <td>0.718997</td>\n",
       "      <td>2.163284</td>\n",
       "      <td>0.875125</td>\n",
       "      <td>-1.890218</td>\n",
       "      <td>-0.743369</td>\n",
       "      <td>-3.590184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  0.949688  0.775597  0.913830  0.013655  0.560499  0.360725  0.943691   \n",
       "1  0.045952  0.027912  0.061524  0.763515  0.304402  0.387798  0.660480   \n",
       "2  0.247389  0.477492  0.179739  0.722179  0.864501  0.384944  0.435235   \n",
       "3  0.060205  0.668670  0.793216  0.888407  0.549063  0.686823  0.242603   \n",
       "4  0.003561  0.827269  0.506180  0.293190  0.998661  0.913623  0.141839   \n",
       "\n",
       "         x7        x8        y0        y1        y2        y3        y4  \n",
       "0  0.833470  0.484945 -3.641941 -0.641199 -1.824330 -6.095105 -0.794640  \n",
       "1  0.216121  0.160511  0.672789  0.681849 -2.240863 -0.620841 -2.184313  \n",
       "2  0.607522  0.549980  1.831997  0.664697 -2.806331 -2.496279 -2.345635  \n",
       "3  0.949293  0.024834  1.152319  0.949221 -1.641698 -3.124831 -4.091910  \n",
       "4  0.339410  0.718997  2.163284  0.875125 -1.890218 -0.743369 -3.590184  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "\n",
    "#define 9 dimensional x (input) numpy array\n",
    "x = np.zeros(9, np.float64)\n",
    "\n",
    "#define 5 dimensional y (output) numpy array\n",
    "y = np.zeros(5, np.float64)\n",
    "\n",
    "#define y functions\n",
    "# y[0] = (2 * x[0] * x[1] * x[2]) + (x[3] * x[4]) - (3 * x[5] * x[6] * x[7]) - (7 * x[0] ** 2 * x[7]) + (2 * x[4])\n",
    "# y[1] = (2 * x[0] * x[4] * x[5]) - (x[2] * x[3] - 3 * x[1] * x[2] * x[3]) - x[2] ** 2 * x[4] - (2 * x[6] * x[7]) + 1\n",
    "# y[2] = (x[2] ** 2) - (x[4] * x[6]) - (3 * x[0] * x[3] * x[5]) - (12 * x[0] ** 2 * x[1] * x[3]) - 2\n",
    "# y[3] = (x[5] ** 3) - (5 * x[0] * x[2] * x[7]) - (x[0] * x[3] * x[6]) - (2 * x[4] ** 2 * x[1] * x[3]) - 3 * x[7]\n",
    "# y[4] = (x[2] ** 2 * x[4]) - (2 * x[2] * x[3] * x[7]) - (x[0] * x[1] * x[3]) - (3 * x[5]) + (x[0] ** 2 * x[6]) - 1\n",
    "\n",
    "fh = open(\"training_data.txt\",\"w\")\n",
    "\n",
    "\n",
    "#generate random inputs for every iteration\n",
    "def generate_random_x():\n",
    "    for index, x_i in enumerate(x):\n",
    "        #x[index] = rnd.uniform(0, 100)\n",
    "        x[index] = rnd.random()\n",
    "        # x[index] = rnd.randint(0, 10000)\n",
    "        \n",
    "def calculate_y():\n",
    "    generate_random_x()\n",
    "    # y1 = 2*x1 * x2 * x3 + x4 * x5 - 3*x6 * x7 * x8 - 7*x1^2 * x8 + 2*x5\n",
    "    # if index == 0:\n",
    "    y[0] = (2 * x[0] * x[1] * x[2]) + (x[3] * x[4]) - (3 * x[5] * x[6] * x[7]) - (7 * x[0] ** 2 * x[7]) + (2 * x[4])\n",
    "    # elif index == 1:\n",
    "    y[1] = (2 * x[0] * x[4] * x[5]) - (x[2] * x[3] - 3 * x[1] * x[2] * x[3]) - x[2] ** 2 * x[4] - (\n",
    "            2 * x[6] * x[7]) + 1\n",
    "    # elif index == 2:\n",
    "    y[2] = (x[2] ** 2) - (x[4] * x[6]) - (3 * x[0] * x[3] * x[5]) - (12 * x[0] ** 2 * x[1] * x[3]) - 2\n",
    "    # elif index == 3:\n",
    "    y[3] = (x[5] ** 3) - (5 * x[0] * x[2] * x[7]) - (x[0] * x[3] * x[6]) - (2 * x[4] ** 2 * x[1] * x[3]) - 3 * x[7]\n",
    "    # elif index == 4:\n",
    "    y[4] = (x[2] ** 2 * x[4]) - (2 * x[2] * x[3] * x[7]) - (x[0] * x[1] * x[3]) - (3 * x[5]) + (\n",
    "            x[0] ** 2 * x[6]) - 1\n",
    "\n",
    "    # write x to file\n",
    "    for x_i in x:\n",
    "        fh.write(str(x_i))\n",
    "        fh.write(\" \")\n",
    "\n",
    "    # write y to file\n",
    "    for y_i in range(0, 5, 1):\n",
    "        # if index == y_i:\n",
    "        # some noise added.\n",
    "        y[y_i] += y[y_i] * 0.001\n",
    "        fh.write(str(y[y_i]))\n",
    "        # else:\n",
    "        #    fh.write(\"0\")\n",
    "\n",
    "        if y_i != 4:\n",
    "            fh.write(\" \")\n",
    "\n",
    "    # fh.write(' y' + str(index))\n",
    "    fh.write(\"\\n\")\n",
    "\n",
    "#generate 600 training samples.\n",
    "for i in range(0, 120, 1):\n",
    "\n",
    "    for j in range(0, 5, 1):\n",
    "        calculate_y()\n",
    "\n",
    "fh.close()\n",
    "\n",
    "column_names = ['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'y0', 'y1', 'y2', 'y3', 'y4']\n",
    "\n",
    "df = pd.read_csv(\"training_data.txt\", header=None, delimiter=' ')\n",
    "\n",
    "df.columns = column_names\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Generating Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.245240</td>\n",
       "      <td>0.665468</td>\n",
       "      <td>0.852349</td>\n",
       "      <td>0.419237</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.390344</td>\n",
       "      <td>0.015568</td>\n",
       "      <td>0.802645</td>\n",
       "      <td>0.239940</td>\n",
       "      <td>-0.059627</td>\n",
       "      <td>1.327806</td>\n",
       "      <td>-1.595342</td>\n",
       "      <td>-3.188963</td>\n",
       "      <td>-2.807725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.866565</td>\n",
       "      <td>0.477839</td>\n",
       "      <td>0.047084</td>\n",
       "      <td>0.550067</td>\n",
       "      <td>0.546208</td>\n",
       "      <td>0.828741</td>\n",
       "      <td>0.449013</td>\n",
       "      <td>0.105061</td>\n",
       "      <td>0.668783</td>\n",
       "      <td>0.762321</td>\n",
       "      <td>1.700198</td>\n",
       "      <td>-5.796687</td>\n",
       "      <td>-0.138291</td>\n",
       "      <td>-3.381047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.289119</td>\n",
       "      <td>0.617810</td>\n",
       "      <td>0.069320</td>\n",
       "      <td>0.502118</td>\n",
       "      <td>0.913223</td>\n",
       "      <td>0.067608</td>\n",
       "      <td>0.907567</td>\n",
       "      <td>0.977245</td>\n",
       "      <td>0.437590</td>\n",
       "      <td>1.558051</td>\n",
       "      <td>-0.712813</td>\n",
       "      <td>-3.164619</td>\n",
       "      <td>-3.678529</td>\n",
       "      <td>-1.280291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.205031</td>\n",
       "      <td>0.769512</td>\n",
       "      <td>0.967749</td>\n",
       "      <td>0.973120</td>\n",
       "      <td>0.862486</td>\n",
       "      <td>0.759072</td>\n",
       "      <td>0.583365</td>\n",
       "      <td>0.250493</td>\n",
       "      <td>0.311933</td>\n",
       "      <td>2.463166</td>\n",
       "      <td>1.400750</td>\n",
       "      <td>-2.398705</td>\n",
       "      <td>-1.793095</td>\n",
       "      <td>-3.070272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.390535</td>\n",
       "      <td>0.413843</td>\n",
       "      <td>0.181294</td>\n",
       "      <td>0.827234</td>\n",
       "      <td>0.425575</td>\n",
       "      <td>0.614009</td>\n",
       "      <td>0.637540</td>\n",
       "      <td>0.689055</td>\n",
       "      <td>0.481282</td>\n",
       "      <td>-0.283054</td>\n",
       "      <td>0.347733</td>\n",
       "      <td>-3.460110</td>\n",
       "      <td>-2.409584</td>\n",
       "      <td>-3.071181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  0.245240  0.665468  0.852349  0.419237  0.006081  0.390344  0.015568   \n",
       "1  0.866565  0.477839  0.047084  0.550067  0.546208  0.828741  0.449013   \n",
       "2  0.289119  0.617810  0.069320  0.502118  0.913223  0.067608  0.907567   \n",
       "3  0.205031  0.769512  0.967749  0.973120  0.862486  0.759072  0.583365   \n",
       "4  0.390535  0.413843  0.181294  0.827234  0.425575  0.614009  0.637540   \n",
       "\n",
       "         x7        x8        y0        y1        y2        y3        y4  \n",
       "0  0.802645  0.239940 -0.059627  1.327806 -1.595342 -3.188963 -2.807725  \n",
       "1  0.105061  0.668783  0.762321  1.700198 -5.796687 -0.138291 -3.381047  \n",
       "2  0.977245  0.437590  1.558051 -0.712813 -3.164619 -3.678529 -1.280291  \n",
       "3  0.250493  0.311933  2.463166  1.400750 -2.398705 -1.793095 -3.070272  \n",
       "4  0.689055  0.481282 -0.283054  0.347733 -3.460110 -2.409584 -3.071181  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fh_test = open(\"test_data.txt\", \"w\")\n",
    "\n",
    "def calculate_test_y():\n",
    "    generate_random_x()\n",
    "    # y1 = 2*x1 * x2 * x3 + x4 * x5 - 3*x6 * x7 * x8 - 7*x1^2 * x8 + 2*x5\n",
    "    # if index == 0:\n",
    "    y[0] = (2 * x[0] * x[1] * x[2]) + (x[3] * x[4]) - (3 * x[5] * x[6] * x[7]) - (7 * x[0] ** 2 * x[7]) + (2 * x[4])\n",
    "    # elif index == 1:\n",
    "    y[1] = (2 * x[0] * x[4] * x[5]) - (x[2] * x[3] - 3 * x[1] * x[2] * x[3]) - x[2] ** 2 * x[4] - (\n",
    "            2 * x[6] * x[7]) + 1\n",
    "    # elif index == 2:\n",
    "    y[2] = (x[2] ** 2) - (x[4] * x[6]) - (3 * x[0] * x[3] * x[5]) - (12 * x[0] ** 2 * x[1] * x[3]) - 2\n",
    "    # elif index == 3:\n",
    "    y[3] = (x[5] ** 3) - (5 * x[0] * x[2] * x[7]) - (x[0] * x[3] * x[6]) - (2 * x[4] ** 2 * x[1] * x[3]) - 3 * x[7]\n",
    "    # elif index == 4:\n",
    "    y[4] = (x[2] ** 2 * x[4]) - (2 * x[2] * x[3] * x[7]) - (x[0] * x[1] * x[3]) - (3 * x[5]) + (\n",
    "            x[0] ** 2 * x[6]) - 1\n",
    "\n",
    "    # write x to file\n",
    "    for x_i in x:\n",
    "        fh_test.write(str(x_i))\n",
    "        fh_test.write(\" \")\n",
    "\n",
    "    # write y to file\n",
    "    for y_i in range(0, 5, 1):\n",
    "        # if index == y_i:\n",
    "        fh_test.write(str(y[y_i]))\n",
    "        # else:\n",
    "        #    fh.write(\"0\")\n",
    "\n",
    "        if y_i != 4:\n",
    "            fh_test.write(\" \")\n",
    "\n",
    "    # fh.write(' y' + str(index))\n",
    "    fh_test.write(\"\\n\")\n",
    "    \n",
    "#generate 100 test samples.    \n",
    "for i in range(0, 20, 1):\n",
    "    for j in range(0, 5, 1):\n",
    "        calculate_test_y()\n",
    "\n",
    "fh_test.close()\n",
    "    \n",
    "df_test = pd.read_csv(\"test_data.txt\", header=None, delimiter=' ')\n",
    "\n",
    "df_test.columns = column_names\n",
    "\n",
    "df_test.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training dataset\n",
    "training_dataset = np.loadtxt(\"training_data.txt\", delimiter=' ')\n",
    "\n",
    "X_Train = training_dataset[:, 0:9]\n",
    "Y_Train = training_dataset[:, 9:14]\n",
    "\n",
    "#load test dataset\n",
    "test_dataset = np.loadtxt(\"test_data.txt\", delimiter=' ')\n",
    "\n",
    "X_Test = test_dataset[:, 0:9]\n",
    "Y_Test = test_dataset[:, 9:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating Model\n",
    "We have 9 inputs and 5 outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 576us/step\n",
      "100/100 [==============================] - 0s 88us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.01\n",
      "Activation tanh\n",
      "Hidden_1 4\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.246952\n",
      "Test Loss: 0.236486 \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation\n",
    "\n",
    "#set different parameters here.\n",
    "def generate_and_train_model(X_Train,Y_Train,X_Test,Y_Test,activation,hidden_1,hidden_2,hidden_3,learning_rate,epoch_size):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(9, input_dim=9))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(hidden_1))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(hidden_2))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(hidden_3))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    sgd = optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "    model.fit(X_Train, Y_Train, epochs=epoch_size, verbose=0)\n",
    "\n",
    "    training_scores = model.evaluate(X_Train, Y_Train)\n",
    "\n",
    "    test_scores = model.evaluate(X_Test, Y_Test)\n",
    "\n",
    "    print(\"Epoch_size: \" + str(epoch_size))\n",
    "    print(\"Learning Rate: \" + str(learning_rate))\n",
    "    print(\"Activation \" + str(activation))\n",
    "    print(\"Hidden_1 \" + str(hidden_1))\n",
    "    print(\"Hidden_2 \" + str(hidden_2))\n",
    "    print(\"Hidden_3 \" + str(hidden_3))\n",
    "\n",
    "    print(\"Train Loss: %f\" % training_scores)\n",
    "    print(\"Test Loss: %f \" % test_scores)\n",
    "    \n",
    "    \n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.01, 500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.01, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.01, 1500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.1, 500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.1, 1500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.5, 500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.5, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 4, 4, 4, 0.5, 1500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"relu\", 4, 4, 4, 0.01, 500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"relu\", 4, 4, 4, 0.01, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"relu\", 4, 4, 4, 0.01, 1500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"relu\", 4, 4, 4, 0.1, 500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"relu\", 4, 4, 4, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"relu\", 4, 4, 4, 0.1, 1500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"sigmoid\", 4, 4, 4, 0.1, 500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"sigmoid\", 4, 4, 4, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"sigmoid\", 4, 4, 4, 0.1, 1500)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"sigmoid\", 4, 4, 4, 0.01, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"sigmoid\", 4, 4, 4, 0.2, 1500)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data Size | Input Node | Input Act | Dense-1 | Dense-1 Act | Dense-2 | Dense-2 Act | Dense-3 | Dense-3 Act | Output Node | Output Act | L.Rate | Epoch | Train Error | Test Error |\n",
    "|:---------:|:----------:|:---------:|:-------:|:-----------:|:-------:|:-----------:|:-------:|:-----------:|:-----------:|:----------:|:------:|:-----:|:-----------:|:----------:|\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.242384  |  0.296860  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  1500 |   0.126778  |  0.167803  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  2000 |   0.217331  |  0.260438  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.1  |  1000 |   0.218391  |  0.280169  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.1  |  1500 |   0.190859  |  0.242867  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.1  |  2000 |   0.179826  |  0.242151  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.5  |  1000 |   0.410062  |  0.473462  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.5  |  1500 |   0.569335  |  0.677881  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.5  |  2000 |   0.345615  |  0.403062  |\n",
    "|    600    |      9     |    relu   |    4    |     relu    |    4    |     relu    |    4    |     relu    |      5      |   linear   |  0.01  |  1000 |   1.822732  |  2.347571  |\n",
    "|    600    |      9     |    relu   |    4    |     relu    |    4    |     relu    |    4    |     relu    |      5      |   linear   |  0.01  |  1500 |   0.805988  |  0.992025  |\n",
    "|    600    |      9     |    relu   |    4    |     relu    |    4    |     relu    |    4    |     relu    |      5      |   linear   |  0.01  |  2000 |   0.462038  |  0.488292  |\n",
    "|    600    |      9     |    relu   |    4    |     tanh    |    4    |     relu    |    4    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.283931  |  0.325317  |\n",
    "|    600    |      9     |    relu   |    4    |     tanh    |    4    |     relu    |    4    |     tanh    |      5      |   linear   |  0.01  |  1500 |   0.397254  |  0.421426  |\n",
    "|    600    |      9     |    relu   |    4    |     tanh    |    4    |     relu    |    4    |     tanh    |      5      |   linear   |  0.01  |  2000 |   0.230768  |  0.269217  |\n",
    "|    600    |      9     |    tanh   |    6    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.230664  |  0.284872  |\n",
    "|    600    |      9     |    tanh   |    6    |     tanh    |    6    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.107739  |  0.147939  |\n",
    "|    600    |      9     |    tanh   |    6    |     tanh    |    6    |     tanh    |    6    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.106117  |  0.138951  |\n",
    "|    625    |      9     |    tanh   |    6    |     tanh    |    6    |     tanh    |    6    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.100039  |  0.105181  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding New Nodes to Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 374us/step\n",
      "100/100 [==============================] - 0s 28us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.1\n",
      "Activation tanh\n",
      "Hidden_1 6\n",
      "Hidden_2 4\n",
      "Hidden_3 4\n",
      "Train Loss: 0.179570\n",
      "Test Loss: 0.215564 \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-36c1a10dfa17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgenerate_and_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerate_and_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgenerate_and_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenerate_and_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgenerate_and_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tanh\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-7c7f0eedb728>\u001b[0m in \u001b[0;36mgenerate_and_train_model\u001b[0;34m(X_Train, Y_Train, X_Test, Y_Test, activation, hidden_1, hidden_2, hidden_3, learning_rate, epoch_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtraining_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DevOps/VirtualEnvs/deepEnv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1605\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/DevOps/VirtualEnvs/deepEnv/lib/python3.5/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    212\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DevOps/VirtualEnvs/deepEnv/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2939\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2940\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DevOps/VirtualEnvs/deepEnv/lib/python3.5/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    463\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DevOps/VirtualEnvs/deepEnv/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   5225\u001b[0m       with super(_DefaultGraphStack, self).get_controller(\n\u001b[1;32m   5226\u001b[0m           default) as g, context.graph_mode():\n\u001b[0;32m-> 5227\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5228\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5229\u001b[0m       \u001b[0;31m# If an exception is raised here it may be hiding a related exception in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DevOps/VirtualEnvs/deepEnv/lib/python3.5/site-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36m_mode\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_is_eager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mEAGER_MODE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 6, 4, 4, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 6, 6, 4, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 6, 6, 6, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 8, 6, 6, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 8, 8, 6, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 8, 8, 8, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 10, 8, 8, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 10, 10, 8, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 10, 10, 10, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 12, 10, 10, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 12, 12, 10, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 12, 12, 12, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 14, 12, 12, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 14, 14, 12, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 14, 14, 14, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 16, 14, 14, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 16, 16, 16, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 18, 16, 16, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 18, 18, 18, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 20, 18, 18, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 20, 20, 18, 0.1, 1000)\n",
    "generate_and_train_model(X_Train, Y_Train, X_Test, Y_Test, \"tanh\", 20, 20, 20, 0.1, 1000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Digit Recognition using CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f96cb36ea58>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "mnist_digits = tf.keras.datasets.mnist\n",
    "\n",
    "\n",
    "#mnist_digits.load_data()\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist_digits.load_data()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# Only use this if using iPython\n",
    "image_index = 11 \n",
    "# You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading AlexNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization, Flatten, Dropout\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist_digits.load_data()\n",
    "img_shape = (28,28)\n",
    "\n",
    "\n",
    "\n",
    "#print(x_train[0])\n",
    "print(x_train[0].shape)\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = np.expand_dims(x_train,3)\n",
    "print(x_train.shape)\n",
    "\n",
    "y_train = np.expand_dims(y_train,3)\n",
    "print(y_train[0].shape)\n",
    "\n",
    "#x_train = np.swapaxes(x_train,1,3)\n",
    "#print(x_train[0].shape)\n",
    "\n",
    "\n",
    "l2_reg = 0\n",
    "n_classes=10\n",
    "\n",
    "alexnet = Sequential()\n",
    "\n",
    "alexnet.add(Conv2D(96, (7, 7), input_shape=(28,28,1),\n",
    "                       padding='same', kernel_regularizer=l2(l2_reg)))\n",
    "\n",
    "alexnet.add(Activation('relu'))\n",
    "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "alexnet.add(Conv2D(256, (5, 5), padding='same'))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 3\n",
    "alexnet.add(ZeroPadding2D((1, 1)))\n",
    "alexnet.add(Conv2D(512, (3, 3), padding='same'))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 4\n",
    "alexnet.add(ZeroPadding2D((1, 1)))\n",
    "alexnet.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "# Layer 5\n",
    "alexnet.add(ZeroPadding2D((1, 1)))\n",
    "alexnet.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "alexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Layer 6\n",
    "alexnet.add(Flatten())\n",
    "alexnet.add(Dense(3072))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "alexnet.add(Dropout(0.5))\n",
    "\n",
    "# Layer 7\n",
    "alexnet.add(Dense(4096))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('relu'))\n",
    "alexnet.add(Dropout(0.5))\n",
    "\n",
    "# Layer 8\n",
    "alexnet.add(Dense(n_classes))\n",
    "alexnet.add(BatchNormalization())\n",
    "alexnet.add(Activation('softmax'))\n",
    "\n",
    "alexnet.summary()\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "alexnet.compile(loss='sparse_categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])\n",
    "\n",
    "#validation_split=0.2, shuffle=True\n",
    "alexnet.fit(x_train,y_train, batch_size=64, epochs=1, verbose=2, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
