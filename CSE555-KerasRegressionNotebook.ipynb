{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Model a Deep Feed Forward Network for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Generating Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make some awesome explanation here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094509</td>\n",
       "      <td>0.888690</td>\n",
       "      <td>0.434537</td>\n",
       "      <td>0.541906</td>\n",
       "      <td>0.189211</td>\n",
       "      <td>0.722835</td>\n",
       "      <td>0.640584</td>\n",
       "      <td>0.254331</td>\n",
       "      <td>0.096062</td>\n",
       "      <td>0.184938</td>\n",
       "      <td>1.057663</td>\n",
       "      <td>-2.097157</td>\n",
       "      <td>-0.505338</td>\n",
       "      <td>-3.295643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.987289</td>\n",
       "      <td>0.800200</td>\n",
       "      <td>0.621521</td>\n",
       "      <td>0.985556</td>\n",
       "      <td>0.996277</td>\n",
       "      <td>0.292472</td>\n",
       "      <td>0.149710</td>\n",
       "      <td>0.105079</td>\n",
       "      <td>0.300476</td>\n",
       "      <td>3.228932</td>\n",
       "      <td>2.018992</td>\n",
       "      <td>-11.853106</td>\n",
       "      <td>-2.326171</td>\n",
       "      <td>-2.256239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.637748</td>\n",
       "      <td>0.282461</td>\n",
       "      <td>0.710468</td>\n",
       "      <td>0.473841</td>\n",
       "      <td>0.187506</td>\n",
       "      <td>0.338222</td>\n",
       "      <td>0.613821</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.265362</td>\n",
       "      <td>-0.657680</td>\n",
       "      <td>0.448185</td>\n",
       "      <td>-2.572760</td>\n",
       "      <td>-2.247806</td>\n",
       "      <td>-2.024908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.447019</td>\n",
       "      <td>0.296505</td>\n",
       "      <td>0.528799</td>\n",
       "      <td>0.678879</td>\n",
       "      <td>0.325948</td>\n",
       "      <td>0.797953</td>\n",
       "      <td>0.312114</td>\n",
       "      <td>0.107037</td>\n",
       "      <td>0.842038</td>\n",
       "      <td>0.784440</td>\n",
       "      <td>1.035943</td>\n",
       "      <td>-3.034282</td>\n",
       "      <td>-0.077107</td>\n",
       "      <td>-3.410585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.879610</td>\n",
       "      <td>0.160176</td>\n",
       "      <td>0.876411</td>\n",
       "      <td>0.835359</td>\n",
       "      <td>0.426384</td>\n",
       "      <td>0.587042</td>\n",
       "      <td>0.401835</td>\n",
       "      <td>0.662446</td>\n",
       "      <td>0.335276</td>\n",
       "      <td>-2.603301</td>\n",
       "      <td>0.200334</td>\n",
       "      <td>-3.943553</td>\n",
       "      <td>-4.687033</td>\n",
       "      <td>-3.213601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  0.094509  0.888690  0.434537  0.541906  0.189211  0.722835  0.640584   \n",
       "1  0.987289  0.800200  0.621521  0.985556  0.996277  0.292472  0.149710   \n",
       "2  0.637748  0.282461  0.710468  0.473841  0.187506  0.338222  0.613821   \n",
       "3  0.447019  0.296505  0.528799  0.678879  0.325948  0.797953  0.312114   \n",
       "4  0.879610  0.160176  0.876411  0.835359  0.426384  0.587042  0.401835   \n",
       "\n",
       "         x7        x8        y0        y1         y2        y3        y4  \n",
       "0  0.254331  0.096062  0.184938  1.057663  -2.097157 -0.505338 -3.295643  \n",
       "1  0.105079  0.300476  3.228932  2.018992 -11.853106 -2.326171 -2.256239  \n",
       "2  0.396800  0.265362 -0.657680  0.448185  -2.572760 -2.247806 -2.024908  \n",
       "3  0.107037  0.842038  0.784440  1.035943  -3.034282 -0.077107 -3.410585  \n",
       "4  0.662446  0.335276 -2.603301  0.200334  -3.943553 -4.687033 -3.213601  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "\n",
    "#define 9 dimensional x (input) numpy array\n",
    "x = np.zeros(9, np.float64)\n",
    "\n",
    "#define 5 dimensional y (output) numpy array\n",
    "y = np.zeros(5, np.float64)\n",
    "\n",
    "#define y functions\n",
    "# y[0] = (2 * x[0] * x[1] * x[2]) + (x[3] * x[4]) - (3 * x[5] * x[6] * x[7]) - (7 * x[0] ** 2 * x[7]) + (2 * x[4])\n",
    "# y[1] = (2 * x[0] * x[4] * x[5]) - (x[2] * x[3] - 3 * x[1] * x[2] * x[3]) - x[2] ** 2 * x[4] - (2 * x[6] * x[7]) + 1\n",
    "# y[2] = (x[2] ** 2) - (x[4] * x[6]) - (3 * x[0] * x[3] * x[5]) - (12 * x[0] ** 2 * x[1] * x[3]) - 2\n",
    "# y[3] = (x[5] ** 3) - (5 * x[0] * x[2] * x[7]) - (x[0] * x[3] * x[6]) - (2 * x[4] ** 2 * x[1] * x[3]) - 3 * x[7]\n",
    "# y[4] = (x[2] ** 2 * x[4]) - (2 * x[2] * x[3] * x[7]) - (x[0] * x[1] * x[3]) - (3 * x[5]) + (x[0] ** 2 * x[6]) - 1\n",
    "\n",
    "fh = open(\"training_data.txt\",\"w\")\n",
    "\n",
    "\n",
    "#generate random inputs for every iteration\n",
    "def generate_random_x():\n",
    "    for index, x_i in enumerate(x):\n",
    "        #x[index] = rnd.uniform(0, 100)\n",
    "        x[index] = rnd.random()\n",
    "        # x[index] = rnd.randint(0, 10000)\n",
    "        \n",
    "def calculate_y():\n",
    "    generate_random_x()\n",
    "    # y1 = 2*x1 * x2 * x3 + x4 * x5 - 3*x6 * x7 * x8 - 7*x1^2 * x8 + 2*x5\n",
    "    # if index == 0:\n",
    "    y[0] = (2 * x[0] * x[1] * x[2]) + (x[3] * x[4]) - (3 * x[5] * x[6] * x[7]) - (7 * x[0] ** 2 * x[7]) + (2 * x[4])\n",
    "    # elif index == 1:\n",
    "    y[1] = (2 * x[0] * x[4] * x[5]) - (x[2] * x[3] - 3 * x[1] * x[2] * x[3]) - x[2] ** 2 * x[4] - (\n",
    "            2 * x[6] * x[7]) + 1\n",
    "    # elif index == 2:\n",
    "    y[2] = (x[2] ** 2) - (x[4] * x[6]) - (3 * x[0] * x[3] * x[5]) - (12 * x[0] ** 2 * x[1] * x[3]) - 2\n",
    "    # elif index == 3:\n",
    "    y[3] = (x[5] ** 3) - (5 * x[0] * x[2] * x[7]) - (x[0] * x[3] * x[6]) - (2 * x[4] ** 2 * x[1] * x[3]) - 3 * x[7]\n",
    "    # elif index == 4:\n",
    "    y[4] = (x[2] ** 2 * x[4]) - (2 * x[2] * x[3] * x[7]) - (x[0] * x[1] * x[3]) - (3 * x[5]) + (\n",
    "            x[0] ** 2 * x[6]) - 1\n",
    "\n",
    "    # write x to file\n",
    "    for x_i in x:\n",
    "        fh.write(str(x_i))\n",
    "        fh.write(\" \")\n",
    "\n",
    "    # write y to file\n",
    "    for y_i in range(0, 5, 1):\n",
    "        # if index == y_i:\n",
    "        # some noise added.\n",
    "        y[y_i] += y[y_i] * 0.001\n",
    "        fh.write(str(y[y_i]))\n",
    "        # else:\n",
    "        #    fh.write(\"0\")\n",
    "\n",
    "        if y_i != 4:\n",
    "            fh.write(\" \")\n",
    "\n",
    "    # fh.write(' y' + str(index))\n",
    "    fh.write(\"\\n\")\n",
    "\n",
    "#generate 600 training samples.\n",
    "for i in range(0, 125, 1):\n",
    "\n",
    "    for j in range(0, 5, 1):\n",
    "        calculate_y()\n",
    "\n",
    "fh.close()\n",
    "\n",
    "column_names = ['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8', 'y0', 'y1', 'y2', 'y3', 'y4']\n",
    "\n",
    "df = pd.read_csv(\"training_data.txt\", header=None, delimiter=' ')\n",
    "\n",
    "df.columns = column_names\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Generating Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>y0</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "      <th>y3</th>\n",
       "      <th>y4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.791713</td>\n",
       "      <td>0.520517</td>\n",
       "      <td>0.334399</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>0.358223</td>\n",
       "      <td>0.356804</td>\n",
       "      <td>0.716685</td>\n",
       "      <td>0.850774</td>\n",
       "      <td>0.454570</td>\n",
       "      <td>-3.376884</td>\n",
       "      <td>-0.048423</td>\n",
       "      <td>-2.366127</td>\n",
       "      <td>-3.665661</td>\n",
       "      <td>-1.626699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.843919</td>\n",
       "      <td>0.048050</td>\n",
       "      <td>0.259797</td>\n",
       "      <td>0.069964</td>\n",
       "      <td>0.375362</td>\n",
       "      <td>0.699747</td>\n",
       "      <td>0.454588</td>\n",
       "      <td>0.856862</td>\n",
       "      <td>0.015259</td>\n",
       "      <td>-4.291439</td>\n",
       "      <td>0.623395</td>\n",
       "      <td>-2.255819</td>\n",
       "      <td>-3.195071</td>\n",
       "      <td>-2.784133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.652189</td>\n",
       "      <td>0.298108</td>\n",
       "      <td>0.075187</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.092703</td>\n",
       "      <td>0.131065</td>\n",
       "      <td>0.216503</td>\n",
       "      <td>0.648724</td>\n",
       "      <td>0.478817</td>\n",
       "      <td>-1.721654</td>\n",
       "      <td>0.730097</td>\n",
       "      <td>-2.982462</td>\n",
       "      <td>-2.182639</td>\n",
       "      <td>-1.459545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.996690</td>\n",
       "      <td>0.196555</td>\n",
       "      <td>0.203467</td>\n",
       "      <td>0.625133</td>\n",
       "      <td>0.388275</td>\n",
       "      <td>0.307186</td>\n",
       "      <td>0.506905</td>\n",
       "      <td>0.328540</td>\n",
       "      <td>0.560634</td>\n",
       "      <td>-1.339063</td>\n",
       "      <td>0.836413</td>\n",
       "      <td>-4.194342</td>\n",
       "      <td>-1.642643</td>\n",
       "      <td>-1.607973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.596973</td>\n",
       "      <td>0.921509</td>\n",
       "      <td>0.308967</td>\n",
       "      <td>0.781528</td>\n",
       "      <td>0.891551</td>\n",
       "      <td>0.363780</td>\n",
       "      <td>0.121572</td>\n",
       "      <td>0.353583</td>\n",
       "      <td>0.829124</td>\n",
       "      <td>1.890836</td>\n",
       "      <td>1.642225</td>\n",
       "      <td>-5.601977</td>\n",
       "      <td>-2.540308</td>\n",
       "      <td>-2.563593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x0        x1        x2        x3        x4        x5        x6  \\\n",
       "0  0.791713  0.520517  0.334399  0.046448  0.358223  0.356804  0.716685   \n",
       "1  0.843919  0.048050  0.259797  0.069964  0.375362  0.699747  0.454588   \n",
       "2  0.652189  0.298108  0.075187  0.544444  0.092703  0.131065  0.216503   \n",
       "3  0.996690  0.196555  0.203467  0.625133  0.388275  0.307186  0.506905   \n",
       "4  0.596973  0.921509  0.308967  0.781528  0.891551  0.363780  0.121572   \n",
       "\n",
       "         x7        x8        y0        y1        y2        y3        y4  \n",
       "0  0.850774  0.454570 -3.376884 -0.048423 -2.366127 -3.665661 -1.626699  \n",
       "1  0.856862  0.015259 -4.291439  0.623395 -2.255819 -3.195071 -2.784133  \n",
       "2  0.648724  0.478817 -1.721654  0.730097 -2.982462 -2.182639 -1.459545  \n",
       "3  0.328540  0.560634 -1.339063  0.836413 -4.194342 -1.642643 -1.607973  \n",
       "4  0.353583  0.829124  1.890836  1.642225 -5.601977 -2.540308 -2.563593  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fh_test = open(\"test_data.txt\", \"w\")\n",
    "\n",
    "def calculate_test_y():\n",
    "    generate_random_x()\n",
    "    # y1 = 2*x1 * x2 * x3 + x4 * x5 - 3*x6 * x7 * x8 - 7*x1^2 * x8 + 2*x5\n",
    "    # if index == 0:\n",
    "    y[0] = (2 * x[0] * x[1] * x[2]) + (x[3] * x[4]) - (3 * x[5] * x[6] * x[7]) - (7 * x[0] ** 2 * x[7]) + (2 * x[4])\n",
    "    # elif index == 1:\n",
    "    y[1] = (2 * x[0] * x[4] * x[5]) - (x[2] * x[3] - 3 * x[1] * x[2] * x[3]) - x[2] ** 2 * x[4] - (\n",
    "            2 * x[6] * x[7]) + 1\n",
    "    # elif index == 2:\n",
    "    y[2] = (x[2] ** 2) - (x[4] * x[6]) - (3 * x[0] * x[3] * x[5]) - (12 * x[0] ** 2 * x[1] * x[3]) - 2\n",
    "    # elif index == 3:\n",
    "    y[3] = (x[5] ** 3) - (5 * x[0] * x[2] * x[7]) - (x[0] * x[3] * x[6]) - (2 * x[4] ** 2 * x[1] * x[3]) - 3 * x[7]\n",
    "    # elif index == 4:\n",
    "    y[4] = (x[2] ** 2 * x[4]) - (2 * x[2] * x[3] * x[7]) - (x[0] * x[1] * x[3]) - (3 * x[5]) + (\n",
    "            x[0] ** 2 * x[6]) - 1\n",
    "\n",
    "    # write x to file\n",
    "    for x_i in x:\n",
    "        fh_test.write(str(x_i))\n",
    "        fh_test.write(\" \")\n",
    "\n",
    "    # write y to file\n",
    "    for y_i in range(0, 5, 1):\n",
    "        # if index == y_i:\n",
    "        fh_test.write(str(y[y_i]))\n",
    "        # else:\n",
    "        #    fh.write(\"0\")\n",
    "\n",
    "        if y_i != 4:\n",
    "            fh_test.write(\" \")\n",
    "\n",
    "    # fh.write(' y' + str(index))\n",
    "    fh_test.write(\"\\n\")\n",
    "    \n",
    "#generate 100 test samples.    \n",
    "for i in range(0, 20, 1):\n",
    "    for j in range(0, 5, 1):\n",
    "        calculate_test_y()\n",
    "\n",
    "fh_test.close()\n",
    "    \n",
    "df_test = pd.read_csv(\"test_data.txt\", header=None, delimiter=' ')\n",
    "\n",
    "df_test.columns = column_names\n",
    "\n",
    "df_test.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Loading Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training dataset\n",
    "training_dataset = np.loadtxt(\"training_data.txt\", delimiter=' ')\n",
    "\n",
    "X_Train = training_dataset[:, 0:9]\n",
    "Y_Train = training_dataset[:, 9:14]\n",
    "\n",
    "#load test dataset\n",
    "test_dataset = np.loadtxt(\"test_data.txt\", delimiter=' ')\n",
    "\n",
    "X_Test = test_dataset[:, 0:9]\n",
    "Y_Test = test_dataset[:, 9:14]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Creating Model\n",
    "We have 9 inputs and 5 outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 584us/step\n",
      "100/100 [==============================] - 0s 67us/step\n",
      "Epoch_size: 1000\n",
      "Learning Rate: 0.01\n",
      "Activation tanh\n",
      "Hidden_1 8\n",
      "Hidden_2 6\n",
      "Hidden_3 6\n",
      "Train Loss: 0.093689\n",
      "Test Loss: 0.092102 \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation\n",
    "\n",
    "#set different parameters here.\n",
    "activation=\"tanh\"\n",
    "learning_rate=0.01\n",
    "epoch_size=1000\n",
    "\n",
    "hidden_1 = 8\n",
    "hidden_2 = 6\n",
    "hidden_3 = 6\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(9, input_dim=9))\n",
    "model.add(Activation(activation))\n",
    "model.add(Dense(hidden_1))\n",
    "model.add(Activation(activation))\n",
    "model.add(Dense(hidden_2))\n",
    "model.add(Activation(activation))\n",
    "model.add(Dense(hidden_3))\n",
    "model.add(Activation(activation))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "#model.summary()\n",
    "\n",
    "sgd = optimizers.SGD(lr=learning_rate)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "model.fit(X_Train, Y_Train, epochs=epoch_size, verbose=0)\n",
    "\n",
    "training_scores = model.evaluate(X_Train, Y_Train)\n",
    "\n",
    "test_scores = model.evaluate(X_Test,Y_Test)\n",
    "\n",
    "print(\"Epoch_size: \" + str(epoch_size))\n",
    "print(\"Learning Rate: \" + str(learning_rate))\n",
    "print(\"Activation \" + str(activation))\n",
    "print(\"Hidden_1 \" + str(hidden_1))\n",
    "print(\"Hidden_2 \" + str(hidden_2))\n",
    "print(\"Hidden_3 \" + str(hidden_3))\n",
    "\n",
    "\n",
    "print(\"Train Loss: %f\" % (training_scores))\n",
    "print(\"Test Loss: %f \" % (test_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data Size | Input Node | Input Act | Dense-1 | Dense-1 Act | Dense-2 | Dense-2 Act | Dense-3 | Dense-3 Act | Output Node | Output Act | L.Rate | Epoch | Train Error | Test Error |\n",
    "|:---------:|:----------:|:---------:|:-------:|:-----------:|:-------:|:-----------:|:-------:|:-----------:|:-----------:|:----------:|:------:|:-----:|:-----------:|:----------:|\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.242384  |  0.296860  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  1500 |   0.126778  |  0.167803  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  2000 |   0.217331  |  0.260438  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.1  |  1000 |   0.218391  |  0.280169  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.1  |  1500 |   0.190859  |  0.242867  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.1  |  2000 |   0.179826  |  0.242151  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.5  |  1000 |   0.410062  |  0.473462  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.5  |  1500 |   0.569335  |  0.677881  |\n",
    "|    600    |      9     |    tanh   |    4    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |   0.5  |  2000 |   0.345615  |  0.403062  |\n",
    "|    600    |      9     |    relu   |    4    |     relu    |    4    |     relu    |    4    |     relu    |      5      |   linear   |  0.01  |  1000 |   1.822732  |  2.347571  |\n",
    "|    600    |      9     |    relu   |    4    |     relu    |    4    |     relu    |    4    |     relu    |      5      |   linear   |  0.01  |  1500 |   0.805988  |  0.992025  |\n",
    "|    600    |      9     |    relu   |    4    |     relu    |    4    |     relu    |    4    |     relu    |      5      |   linear   |  0.01  |  2000 |   0.462038  |  0.488292  |\n",
    "|    600    |      9     |    relu   |    4    |     tanh    |    4    |     relu    |    4    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.283931  |  0.325317  |\n",
    "|    600    |      9     |    relu   |    4    |     tanh    |    4    |     relu    |    4    |     tanh    |      5      |   linear   |  0.01  |  1500 |   0.397254  |  0.421426  |\n",
    "|    600    |      9     |    relu   |    4    |     tanh    |    4    |     relu    |    4    |     tanh    |      5      |   linear   |  0.01  |  2000 |   0.230768  |  0.269217  |\n",
    "|    600    |      9     |    tanh   |    6    |     tanh    |    4    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.230664  |  0.284872  |\n",
    "|    600    |      9     |    tanh   |    6    |     tanh    |    6    |     tanh    |    4    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.107739  |  0.147939  |\n",
    "|    600    |      9     |    tanh   |    6    |     tanh    |    6    |     tanh    |    6    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.106117  |  0.138951  |\n",
    "|    625    |      9     |    tanh   |    6    |     tanh    |    6    |     tanh    |    6    |     tanh    |      5      |   linear   |  0.01  |  1000 |   0.100039  |  0.105181  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding New Nodes to Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 Digit Recognition using CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist_digits = tf.keras.datasets.mnist\n",
    "\n",
    "\n",
    "#mnist_digits.load_data()\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist_digits.load_data()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "# Only use this if using iPython\n",
    "image_index = 11 \n",
    "# You may select anything up to 60,000\n",
    "print(y_train[image_index]) # The label is 8\n",
    "plt.imshow(x_train[image_index], cmap='Greys')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading AlexNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "img_shape = (28,28,1)\n",
    "l2_reg = 0\n",
    "\n",
    "alexnet = Sequential()\n",
    "\n",
    "alexnet.add(Conv2D(96, (11, 11), input_shape=img_shape,\n",
    "                       padding='same', kernel_regularizer=l2(l2_reg)))\n",
    "\n",
    "alexnet.add(Activation('relu'))\n",
    "    alexnet.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
